# Eval framework configuration
# CLI tools (claude, codex, copilot) handle their own authentication.
# No API keys needed -- the locally installed CLIs are already authenticated.

cli:
  default: claude           # which CLI tool to use (claude | codex | copilot)
  claude:
    model: haiku            # CLI-native model string (not SDK model ID)
  codex:
    model: o4-mini          # codex model name
  copilot:
    model: null             # copilot picks its own model

temperature: 0.0

retry:
  max_retries: 3
  backoff_base: 2.0
  backoff_jitter: 0.5

cost:
  max_cost_per_run: 5.00    # dollar-based cap (effective when CLI reports cost)
  max_calls_per_run: 500    # call-count cap (always effective; safety net when cost unavailable)

fail_fast:
  consecutive_threshold: 3
  enabled: true

rng:
  default_seed: 42

paths:
  results_dir: results
  baselines_dir: baselines
  rubrics_dir: rubrics
  datasets_dir: datasets
  reports_dir: reports

# Per-eval-type regression thresholds
regression:
  effectiveness:
    mean_drop_threshold: 0.5
    stddev_multiplier: 2
    min_cases_before_compare: 3

  activation:
    tpr_drop_threshold: 0.10
    fpr_increase_threshold: 0.05
    min_cases_before_compare: 5

  size_impact:
    score_change_threshold: 0.5
    min_cases_before_compare: 3

  confusion:
    cross_activation_change_threshold: 0.10
    min_cases_before_compare: 5
