{
  "created_at": "2026-02-21T00:08:07.600158Z",
  "epic": {
    "data": {
      "branch_name": "fn-57-copilot-testing-and-progressive",
      "completion_review_status": "unknown",
      "completion_reviewed_at": null,
      "created_at": "2026-02-21T00:03:17.256428Z",
      "default_impl": null,
      "default_review": null,
      "default_sync": null,
      "depends_on_epics": [
        "fn-56-copilot-structural-compatibility"
      ],
      "id": "fn-57-copilot-testing-and-progressive",
      "next_task": 1,
      "plan_review_status": "unknown",
      "plan_reviewed_at": null,
      "spec_path": ".flow/specs/fn-57-copilot-testing-and-progressive.md",
      "status": "open",
      "title": "Copilot Testing and Progressive Disclosure",
      "updated_at": "2026-02-21T00:04:23.545516Z"
    },
    "spec": "# Copilot Testing and Progressive Disclosure\n\n## Overview\n\nProve that Copilot actually loads and uses dotnet-artisan skills after the structural changes in fn-56, catch regressions in Claude Code and Codex, optimize oversized skills for multi-platform delivery via progressive disclosure, and harden CI to gate on Copilot success.\n\n**Problem:** The plugin currently has no automated proof that Copilot discovers, loads, or correctly uses any skills. The CI workflow has `continue-on-error: true` for Copilot, silently swallowing failures. Additionally, 11+ skills exceed 500 lines and may confuse models or hit platform size limits (per dotnet-skills-evals data: truncation improved results for oversized skills).\n\n## Scope\n\n- Copilot activation smoke tests using dotnet-skills-evals patterns\n- Cross-provider regression tests (Claude Code, Codex, Copilot)\n- Progressive disclosure refactoring for all skills >500 lines (issue #48)\n- CI hardening: Copilot gate, version pinning, frontmatter safety checks\n\n## Out of scope\n\n- Structural directory changes (covered by fn-56)\n- Frontmatter migration (covered by fn-56)\n- New skill content authoring\n\n## Approach\n\n1. **Smoke tests** modeled on dotnet-skills-evals activation eval pattern: test cases with expected_skills, verified against Copilot CLI output\n2. **Regression tests** verify existing Claude Code and Codex behavior unchanged after flatten\n3. **Progressive disclosure** following the Agent Skills spec: SKILL.md core <500 lines with sibling reference files\n4. **CI hardening** incremental: first verify Copilot passes, then remove `continue-on-error`\n\n## Risks\n\n- **Copilot CLI not available in CI runners** \u2192 version-pinned install step in workflow\n- **32-skill limit masks real failures** \u2192 smoke tests must target skills within visible window AND verify advisor-routed skills\n- **Progressive disclosure changes skill behavior** \u2192 before/after effectiveness comparison using eval patterns\n- **Eval framework external dependency** \u2192 pin dotnet-skills-evals version or vendor test patterns\n\n## Quick commands\n\n```bash\n# Run Copilot smoke tests\npython tests/copilot-smoke/run_smoke.py --provider copilot\n\n# Run cross-provider regression\n./test.sh --agents claude,codex,copilot\n\n# Check skill sizes\nfind skills -name SKILL.md -exec wc -l {} + | sort -rn | head -20\n\n# Verify no skill exceeds 500 lines\nfind skills -name SKILL.md -exec sh -c 'lines=$(wc -l < \"$1\"); [ \"$lines\" -gt 500 ] && echo \"OVER: $1 ($lines lines)\"' _ {} \\;\n```\n\n## Acceptance\n\n- [ ] Copilot smoke tests exist and pass: verify skill discovery, activation, and content loading\n- [ ] Claude Code regression tests pass: all existing test cases unchanged\n- [ ] Codex regression tests pass: skill sync works with flat layout\n- [ ] All 11+ oversized skills refactored to <500 lines with sibling reference files\n- [ ] CI workflow gates on Copilot success (continue-on-error removed)\n- [ ] Copilot CLI version pinned in CI workflow\n- [ ] Frontmatter safety checks in CI (no BOM, no quoted descriptions, license present)\n\n## Dependencies\n\n- Depends on fn-56 (structural compatibility) completing first\n- Uses patterns from dotnet-skills-evals (https://github.com/Aaronontheweb/dotnet-skills-evals)\n- References dotnet-skills issue #48 for progressive disclosure requirements\n\n## References\n\n- dotnet-skills-evals: https://github.com/Aaronontheweb/dotnet-skills-evals\n- Issue #48: https://github.com/Aaronontheweb/dotnet-skills/issues/48\n- Copilot CLI issues: #1464 (32-skill limit), #978 (skills not auto-activated)\n- Agent Skills spec progressive disclosure: https://agentskills.io/specification\n- Existing CI: .github/workflows/agent-live-routing.yml, .github/workflows/validate.yml\n"
  },
  "epic_id": "fn-57-copilot-testing-and-progressive",
  "schema_version": 2,
  "tasks": [
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-21T00:04:35.429307Z",
        "depends_on": [],
        "epic": "fn-57-copilot-testing-and-progressive",
        "id": "fn-57-copilot-testing-and-progressive.1",
        "priority": null,
        "spec_path": ".flow/tasks/fn-57-copilot-testing-and-progressive.1.md",
        "status": "todo",
        "title": "Copilot activation smoke tests",
        "updated_at": "2026-02-21T00:06:36.237484Z"
      },
      "id": "fn-57-copilot-testing-and-progressive.1",
      "runtime": null,
      "spec": "# fn-57-copilot-testing-and-progressive.1 Copilot activation smoke tests\n\n## Description\nCreate Copilot-specific activation smoke tests that prove skills are discovered, loaded, and correctly used by Copilot CLI. Model test patterns after the dotnet-skills-evals activation eval framework.\n\n**Size:** M\n**Files:** tests/copilot-smoke/ (new directory), tests/copilot-smoke/cases.jsonl (test cases), tests/copilot-smoke/run_smoke.py (runner)\n\n## Approach\n\n1. **Study dotnet-skills-evals activation eval** at `src/dotnet_skills_evals/eval_activation/`. The framework tests three discovery mechanisms: `tool` (function calling), `compressed` (terse index), `fat` (full descriptions). Our smoke tests should mirror the `tool` mechanism since that matches how Copilot discovers skills.\n\n2. **Create test case dataset** in JSONL format matching dotnet-skills-evals schema:\n   ```\n   {\"id\": \"smoke-001\", \"user_prompt\": \"...\", \"expected_skills\": [\"skill-name\"], \"should_activate\": true, \"category\": \"...\"}\n   ```\n   Cover:\n   - **Top 32 visible skills**: Direct activation via prompt matching description\n   - **Advisor-routed skills**: Prompts that should trigger `dotnet-advisor` which then routes to skills outside top 32\n   - **Negative controls**: Prompts that should NOT trigger any .NET skills (e.g., Python, JavaScript topics)\n   - Minimum 20 test cases (10 direct, 5 advisor-routed, 5 negative)\n\n3. **Build smoke runner** that:\n   - Invokes Copilot CLI with each test prompt\n   - Parses output for evidence of skill loading (regex: `Base directory for this skill:\\s*(?<path>.+)`)\n   - Compares activated skills against expected_skills\n   - Reports pass/fail with activation rates\n\n4. **Integrate with existing test harness**. The `copilot-refactor` branch already has `run-agent-routing-smoke.py` and `compare-agent-routing-baseline.py` \u2014 extend rather than replace. Version-keyed baseline JSONs already exist.\n\n5. **Test advisor meta-routing specifically**: Verify that when the advisor is activated, skills referenced in its compressed catalog can be subsequently loaded on demand.\n\n## Key context\n\n- dotnet-skills-evals `loader.py` scans one level deep only \u2014 matches our flat layout\n- The eval framework found compressed-index discovery at 56.5% TPR (best for Sonnet)\n- Existing `tests/agent-routing/cases.json` has routing test cases \u2014 Copilot smoke tests are complementary but distinct (activation vs routing accuracy)\n- Copilot CLI evidence pattern: `Base directory for this skill:\\s*(?<path>.+)` (from `docs/agent-routing-tests.md:L111`)\n- Copilot issue #978: \"Skills not auto-activated\" \u2014 test descriptions must use strong activation language\n## Acceptance\n- [ ] Test case dataset exists with >= 20 cases (10 direct, 5 advisor-routed, 5 negative)\n- [ ] Smoke runner can invoke Copilot CLI and parse skill activation evidence\n- [ ] Direct activation: >= 8/10 top-32 skills correctly activated by matching prompts\n- [ ] Advisor routing: >= 3/5 advisor-routed prompts correctly chain through advisor to target skill\n- [ ] Negative controls: 0/5 false activations for non-.NET prompts\n- [ ] Results output in a format compatible with `compare-agent-routing-baseline.py`\n- [ ] Runner handles Copilot CLI not installed gracefully (skip with warning, not crash)\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-21T00:04:35.546989Z",
        "depends_on": [],
        "epic": "fn-57-copilot-testing-and-progressive",
        "id": "fn-57-copilot-testing-and-progressive.2",
        "priority": null,
        "spec_path": ".flow/tasks/fn-57-copilot-testing-and-progressive.2.md",
        "status": "todo",
        "title": "Cross-provider regression tests",
        "updated_at": "2026-02-21T00:06:53.216294Z"
      },
      "id": "fn-57-copilot-testing-and-progressive.2",
      "runtime": null,
      "spec": "# fn-57-copilot-testing-and-progressive.2 Cross-provider regression tests\n\n## Description\nVerify that Claude Code, Codex, and Copilot all correctly discover and use skills after the structural changes in fn-56. Catch regressions early by comparing against pre-flatten baselines.\n\n**Size:** M\n**Files:** tests/agent-routing/ (existing), test.sh, tests/agent-routing/provider-baseline.json, .github/workflows/agent-live-routing.yml\n\n## Approach\n\n1. **Pre-flatten baseline capture**: Before fn-56 work begins, run the existing test suite and capture baselines per provider. Store as version-keyed JSONs (the `copilot-refactor` branch pattern already does this).\n\n2. **Post-flatten verification for Claude Code**:\n   - Run `./test.sh --agents claude` \u2014 verify all existing test cases pass\n   - Key check: `plugin.json` paths resolve correctly from Claude Code's plugin loader\n   - Key check: `[skill:name]` cross-references still resolve (validator already checks this)\n   - Key check: hooks still find scripts via `${CLAUDE_PLUGIN_ROOT}` (path-independent, should be fine)\n\n3. **Post-flatten verification for Codex**:\n   - Run `./test.sh --agents codex` \u2014 verify skill sync works\n   - Key check: `test.sh:129` find depth fix from fn-56.1 actually works (finds 131 skill dirs)\n   - Key check: `.agents/openai.yaml` path pattern updated\n\n4. **Post-flatten verification for Copilot**:\n   - Run `./test.sh --agents copilot`\n   - Key check: Copilot can discover at least 32 skills from flat layout\n   - Key check: Evidence pattern `Base directory for this skill:` appears in output\n\n5. **Compare baselines**: Run `compare-agent-routing-baseline.py` to diff pre/post results. Flag any regressions.\n\n6. **Update `provider-baseline.json`** with new expected pass/fail per provider per test case if behavior intentionally changes.\n\n## Key context\n\n- `test.sh` already handles per-provider setup: `prepare_claude_plugin()`, `prepare_codex_plugin()`, `prepare_copilot_plugin()` (L89-108)\n- `provider-baseline.json` defines expected pass/fail per provider per test case\n- The `copilot-refactor` branch already has `run-agent-routing-smoke.py` and `compare-agent-routing-baseline.py`\n- CI matrix: `.github/workflows/agent-live-routing.yml` runs claude, codex, copilot\n- Copilot currently has `continue-on-error: true` \u2014 regressions are silently swallowed\n## Acceptance\n- [ ] Pre-flatten baseline captured and stored as version-keyed JSON\n- [ ] Claude Code: all existing test cases pass on flat layout\n- [ ] Codex: skill sync discovers 131 skills from flat layout\n- [ ] Copilot: discovers >= 32 skills from flat layout\n- [ ] Baseline comparison shows no unintentional regressions\n- [ ] `provider-baseline.json` updated with any intentional behavior changes + justification comments\n- [ ] All three providers can be tested via `./test.sh --agents claude,codex,copilot`\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-21T00:04:35.668788Z",
        "depends_on": [],
        "epic": "fn-57-copilot-testing-and-progressive",
        "id": "fn-57-copilot-testing-and-progressive.3",
        "priority": null,
        "spec_path": ".flow/tasks/fn-57-copilot-testing-and-progressive.3.md",
        "status": "todo",
        "title": "Progressive disclosure for oversized skills",
        "updated_at": "2026-02-21T00:07:14.957380Z"
      },
      "id": "fn-57-copilot-testing-and-progressive.3",
      "runtime": null,
      "spec": "# fn-57-copilot-testing-and-progressive.3 Progressive disclosure for oversized skills\n\n## Description\nRefactor all oversized skills (>500 lines) into progressive disclosure format: core SKILL.md (<500 lines) plus sibling reference files. Per dotnet-skills-evals data, truncation actually improved results for oversized skills \u2014 extra content was \"actively confusing\" the model.\n\n**Size:** M (repetitive pattern across 11+ skills)\n**Files:** skills/dotnet-mermaid-diagrams/, skills/dotnet-grpc/, skills/dotnet-roslyn-analyzers/, skills/dotnet-terminal-gui/, skills/dotnet-observability/, skills/dotnet-system-commandline/, skills/dotnet-xml-docs/, skills/dotnet-ado-patterns/, skills/dotnet-maui-development/, skills/dotnet-architecture-patterns/, skills/dotnet-msbuild-tasks/ (and any others >500 lines)\n\n## Approach\n\nFor each oversized skill:\n\n1. **Identify content tiers**:\n   - **Core** (SKILL.md): Problem space, key patterns, routing rules, scope/OOS, essential gotchas \u2014 must stay under 500 lines\n   - **Examples** (examples.md): Detailed code examples, before/after patterns\n   - **Reference** (reference.md): API reference, configuration options, complete parameter lists\n   - **Common mistakes** (common-mistakes.md): Anti-patterns, debugging tips, migration gotchas\n\n2. **Extract to sibling files**: Move detailed content from SKILL.md into appropriate sibling files. Add `[skill:name]` cross-references in the core SKILL.md pointing to the reference files.\n\n3. **Preserve `[skill:]` cross-references**: Any cross-references in extracted content must be preserved in the sibling files. The validator checks references in SKILL.md only, so sibling references are informational (not validated).\n\n4. **Verify line counts**: Each refactored SKILL.md must be under 500 lines. Use `wc -l` to verify.\n\n**Priority order** (by size, most oversized first):\n1. dotnet-mermaid-diagrams (874 lines)\n2. dotnet-grpc (856 lines)\n3. dotnet-roslyn-analyzers (770 lines)\n4. dotnet-terminal-gui (754 lines)\n5. dotnet-observability (739 lines)\n6. dotnet-system-commandline (731 lines)\n7. dotnet-xml-docs (687 lines)\n8. dotnet-ado-patterns (682 lines)\n9. dotnet-maui-development (674 lines)\n10. dotnet-architecture-patterns (672 lines)\n11. dotnet-msbuild-tasks (665 lines)\n\n## Key context\n\n- Agent Skills spec recommends SKILL.md under 500 lines with sibling files for overflow\n- dotnet-skills-evals data: For akka-net-management (685 lines), truncation to 500 lines IMPROVED results\n- Both Claude Code and Copilot support multi-file skill directories with progressive disclosure\n- Copilot comment in dotnet-skills-evals: `main_only_context` \u2014 \"Just the main SKILL.md - what a platform like Copilot would see\"\n- The `dotnet-windbg-debugging` skill already uses a `reference/` directory with 16 files \u2014 this is the existing pattern to follow\n- Two skills already use `details.md` companion files (`dotnet-csharp-code-smells`, `dotnet-roslyn-analyzers`)\n## Acceptance\n- [ ] All 11 identified skills have SKILL.md under 500 lines\n- [ ] Each refactored skill has at least one sibling file (examples.md, reference.md, or common-mistakes.md)\n- [ ] No content is lost \u2014 all extracted content exists in sibling files\n- [ ] Core SKILL.md files retain routing essentials: scope, OOS, key patterns, cross-references\n- [ ] `[skill:]` cross-references preserved in both core and sibling files\n- [ ] `./scripts/validate-skills.sh` passes after changes\n- [ ] `find skills -name SKILL.md -exec sh -c 'lines=$(wc -l < \"$1\"); [ \"$lines\" -gt 500 ] && echo \"$1: $lines\"' _ {} \\;` returns zero matches\n- [ ] Sibling file naming follows existing convention (reference/, examples.md, details.md)\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-21T00:04:35.788124Z",
        "depends_on": [
          "fn-57-copilot-testing-and-progressive.1",
          "fn-57-copilot-testing-and-progressive.2"
        ],
        "epic": "fn-57-copilot-testing-and-progressive",
        "id": "fn-57-copilot-testing-and-progressive.4",
        "priority": null,
        "spec_path": ".flow/tasks/fn-57-copilot-testing-and-progressive.4.md",
        "status": "todo",
        "title": "CI hardening for Copilot gate",
        "updated_at": "2026-02-21T00:07:33.294787Z"
      },
      "id": "fn-57-copilot-testing-and-progressive.4",
      "runtime": null,
      "spec": "# fn-57-copilot-testing-and-progressive.4 CI hardening for Copilot gate\n\n## Description\nHarden CI to make Copilot a non-optional gate, pin Copilot CLI version, and add frontmatter safety checks to prevent regression.\n\n**Size:** M\n**Files:** .github/workflows/validate.yml, .github/workflows/agent-live-routing.yml, scripts/_validate_skills.py\n\n## Approach\n\n1. **Remove `continue-on-error` for Copilot**: In `.github/workflows/agent-live-routing.yml:L31`, change `continue-on-error: ${{ matrix.agent == 'copilot' }}` to `continue-on-error: false` (or remove the line). This makes Copilot a hard gate like Claude and Codex.\n\n2. **Pin Copilot CLI version in CI**: Add a version-pinned Copilot CLI install step to the workflow. Use the version tested against (currently v0.0.413). This prevents surprise breakage from upstream CLI updates.\n\n3. **Add frontmatter safety checks to `validate.yml`**: Extend the existing validation workflow to include Copilot-specific checks:\n   - No UTF-8 BOM in any SKILL.md\n   - No double-quoted description values\n   - `license:` field present in all SKILL.md files\n   - No `metadata:` as last frontmatter field\n   - No SKILL.md nested more than 1 level under skills/\n   These checks may already be in `_validate_skills.py` (added in fn-56.3) \u2014 verify they run in CI.\n\n4. **Add skill count assertion**: CI should verify `find skills -name SKILL.md -maxdepth 2 | wc -l` matches expected count (131). Catches accidental skill deletion or mis-nesting.\n\n5. **Define exit criteria documentation**: Add a section to `docs/agent-routing-tests.md` documenting:\n   - What \"Copilot passes\" means (evidence patterns, minimum activation rate)\n   - When to temporarily re-enable `continue-on-error` (e.g., known Copilot CLI bug upstream)\n   - How to update baselines when intentional behavior changes\n\n## Key context\n\n- Current CI matrix: `strategy: matrix: agent: [claude, codex, copilot]`\n- Copilot has been soft-failure since the routing harness was created (fn-54)\n- The `summarize` job hardcodes `PROVIDERS=(claude codex copilot)` \u2014 if Copilot isn't installed, summarize fails with `ERROR: No results found for provider 'copilot'`\n- Copilot CLI is distributed via npm (`@anthropic-ai/copilot-cli` or similar) \u2014 version pinning uses `npm install -g copilot-cli@0.0.413`\n## Acceptance\n- [ ] `continue-on-error` removed for Copilot in agent-live-routing.yml\n- [ ] Copilot CLI version pinned in CI workflow install step\n- [ ] Frontmatter safety checks run in CI (BOM, quoted description, license, metadata position)\n- [ ] Flat layout guard runs in CI (no nested SKILL.md)\n- [ ] Skill count assertion in CI (expected: 131)\n- [ ] Exit criteria documented in docs/agent-routing-tests.md\n- [ ] CI workflow passes with all three providers as hard gates\n- [ ] Copilot CLI install step handles unavailability gracefully (clear error, not silent skip)\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    }
  ]
}
