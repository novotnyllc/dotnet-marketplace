{
  "created_at": "2026-02-19T03:55:21.657717Z",
  "epic": {
    "data": {
      "branch_name": "fn-53-skill-routing-language-hardening",
      "completion_review_status": "unknown",
      "completion_reviewed_at": null,
      "created_at": "2026-02-19T01:47:38.082993Z",
      "default_impl": null,
      "default_review": null,
      "default_sync": null,
      "depends_on_epics": [],
      "id": "fn-53-skill-routing-language-hardening",
      "next_task": 1,
      "plan_review_status": "unknown",
      "plan_reviewed_at": null,
      "spec_path": ".flow/specs/fn-53-skill-routing-language-hardening.md",
      "status": "open",
      "title": "Skill Routing Language Hardening",
      "updated_at": "2026-02-19T03:15:52.140706Z"
    },
    "spec": "# Skill Routing Language Hardening\n\n## Overview\n\nStandardize routing language across all 130 SKILL.md files and 14 agent files so skills are discovered reliably from non-specific prompts. Descriptions stay concise/high-signal within the 12K char budget, inter-skill references use canonical `[skill:name]` syntax everywhere, and scope/out-of-scope boundaries are explicit. Harden validation scripts and CI gates to enforce these standards going forward. Detect and prevent semantic overlap between descriptions that could cause routing confusion.\n\n## Scope\n\n**In scope:**\n- All 130 `skills/**/SKILL.md` files (description, scope, out-of-scope, cross-references)\n- All 14 `agents/*.md` files (bare-text references \u2192 `[skill:]` syntax)\n- `scripts/_validate_skills.py` and `scripts/validate-skills.sh` (new checks)\n- `tests/agent-routing/check-skills.cs` and `cases.json` (assertion hardening)\n- `CONTRIBUTING-SKILLS.md`, `CONTRIBUTING.md`, `CLAUDE.md` (guidance updates)\n- `.github/workflows/validate.yml` (CI gate updates)\n- **Semantic similarity overlap detection** \u2014 stdlib-only multi-signal Python script (`scripts/validate-similarity.py`) that computes pairwise description similarity using set Jaccard + `difflib.SequenceMatcher` + category-aware adjustment. CI-gatable with suppression list for known-acceptable pairs.\n\n**Out of scope:**\n- Changing skill functionality or body content beyond routing sections\n- Adding new skills or removing existing ones\n- Changing the routing architecture (advisor \u2192 domain skill chain)\n- `README.md` delegation flow diagrams (content lives there, not in AGENTS.md)\n- Embedding-based similarity (sentence-transformers, OpenAI embeddings) \u2014 stdlib approach is sufficient for 130 descriptions\n\n## Key Context\n\n- Budget is at WARN threshold: ~12,345 chars current vs 12,000 warn / 15,600 fail (thresholds from `validate-skills.sh --warn-threshold 12000 --fail-threshold 15600`). All description changes must be budget-neutral or budget-negative.\n- Research shows assertive cues in descriptions create 7x selection bias; position bias gives 80.2% selection rate to first-listed tools. Descriptions must be factual, not promotional.\n- 16 skills have zero routing markers (no trigger, scope, or out-of-scope). These need markers added from scratch.\n- 8 of 14 agent files use bare-text references (~50 total) instead of `[skill:]` syntax.\n- CI currently runs without `STRICT_REFS=1`, so cross-ref validation is lenient. Must enable strict mode.\n- Prior art: fn-29 (fleet review), fn-37 (cleanup sweep), fn-49 (compliance review), fn-51 (frontmatter).\n- **Historical reference**: `.flow/specs/skill-routing-language-hardening-plan.md` is the prior plan snapshot. The authoritative plan is THIS spec (`.flow/specs/fn-53-skill-routing-language-hardening.md`).\n\n## Semantic Similarity Detection Design\n\n**Problem**: Two descriptions sharing too much vocabulary cause routing confusion \u2014 the LLM picks the wrong skill. With 130 skills (8,385 pairs), manual review is infeasible.\n\n**Approach**: Multi-signal composite score using Python stdlib only (no numpy, sklearn, sentence-transformers). Standalone script `scripts/validate-similarity.py`.\n\n**Signals and composite formula:**\n\n```\ncomposite = 0.4 * set_jaccard + 0.4 * seqmatcher + (0.15 if same_category else 0.0)\n```\n\n1. **Set Jaccard** (0.4 weight): Tokenize \u2192 lowercase \u2192 strip domain stopwords \u2192 convert to `set(tokens)` \u2192 compute `|A \u2229 B| / |A \u222a B|`. Use `set()`, NOT `Counter` (Jaccard is set-based, not multiset).\n2. **SequenceMatcher ratio** (0.4 weight): `difflib.SequenceMatcher(a, b).ratio()` for structural/character-level similarity. Operates on raw descriptions (NOT stopword-stripped).\n3. **Same-category adjustment** (+0.15 additive): If both items share the same category directory, add +0.15 directly to composite (intra-category overlap is MORE concerning). This is a flat additive boost, not a weighted signal.\n\n**Domain stopwords** (authoritative list \u2014 stripped before set Jaccard only, NOT before SequenceMatcher):\n`dotnet`, `net`, `apps`, `building`, `designing`, `using`, `writing`, `implementing`, `adding`, `creating`, `configuring`, `managing`, `choosing`, `analyzing`, `working`, `patterns`, `for`\n\nThis list is the initial starting point. T13 calibrates empirically: run against all descriptions, identify terms appearing in >30% of descriptions, add them. Changes to the stopword list require regenerating the similarity baseline in the same PR.\n\n**Thresholds** (calibrated against actual data \u2014 max real pair: `dotnet-ado-publish` / `dotnet-gha-publish` at 0.71 SequenceMatcher):\n- **INFO** at composite >= 0.40: reported but not flagged\n- **WARN** at composite >= 0.55: needs review during sweeps\n- **ERROR** at composite >= 0.75: must be differentiated or suppressed\n\n**Canonical pair identity**: Pairs are identified by sorted tuple `(min(id_a, id_b), max(id_a, id_b))`. This ensures deterministic ordering in baseline/suppression files and stable diffs.\n\n**Suppression list** (`scripts/similarity-suppressions.json`): JSON array of `{skill_a, skill_b, rationale}` where `skill_a < skill_b` (sorted). Suppressed pairs:\n- Produce INFO-level output regardless of score\n- Are excluded from \"new WARN\" baseline regression detection\n- Are NOT counted in `PAIRS_ABOVE_WARN` or `PAIRS_ABOVE_ERROR`\n\n**Baseline file** (`scripts/similarity-baseline.json`): JSON with `{version: 1, pairs: [...]}` where pairs are unsuppressed sorted tuples above WARN threshold. Suppressed pairs are excluded from the baseline. Schema-versioned for stable diffs. Sorted output for deterministic git diffs.\n\n**Scope**: Both skill descriptions (130) AND agent descriptions (14) = 144 items, 10,296 pairs. Agent-skill confusion is just as problematic as skill-skill confusion.\n\n**Output**: JSON report to stdout with per-pair detail + summary stats. Stable CI output keys on stderr: `MAX_SIMILARITY_SCORE`, `PAIRS_ABOVE_WARN`, `PAIRS_ABOVE_ERROR`.\n\n**Exit code semantics**:\n- Exit 0: No unsuppressed ERRORs AND no new WARNs (when baseline provided)\n- Exit 1: Any unsuppressed ERROR pairs exist, OR any new WARN+ pairs not in baseline/suppressions (when baseline provided)\n- Exit 2: Script error (bad args, missing files)\n\nBoth conditions are checked; either triggers exit 1. Counts for each condition are emitted separately in summary (`unsuppressed_errors`, `new_warns_vs_baseline`).\n\n**Shared agent frontmatter parser**: Both T3 (`_validate_skills.py`) and T13 (`validate-similarity.py`) need agent description extraction. To prevent divergence, factor the parser into a shared helper module (`scripts/_agent_frontmatter.py`) imported by both scripts.\n\n**Agent description extraction**: Agent frontmatter uses full YAML with sequences. The similarity script extracts `description:` values using a minimal deterministic parser that handles:\n- Plain scalar values: `description: Some text here`\n- Quoted strings (single and double): `description: \"Some text\"`\n- Block scalars (`|` and `>`): multi-line descriptions with indentation\nThis is the same limited subset used by T3's `parse_agent_frontmatter()`. It does NOT handle sequences, flow constructs, or nested mappings \u2014 only the `name:` and `description:` scalar fields.\n\n**CI gate**: T3 wires the similarity script into `validate-skills.sh` and `.github/workflows/validate.yml`. T13 delivers only the standalone script + baseline + suppressions + documented interface.\n\n## Cross-Reference Conventions\n\n**Unified `[skill:]` syntax** \u2014 `[skill:name]` refers to any routable artifact (skills OR agents). The validator resolves references against the union of skill directory names + agent file names. This is consistent with how both skills and agents are loaded via the skill system.\n\n**Self-references** \u2014 A skill referencing itself via `[skill:]` is always an error.\n\n**Cycles** \u2014 Bidirectional references (e.g., `dotnet-advisor` \u2194 `dotnet-version-detection`) are legitimate and expected for hub skills. Cycle detection produces a **report** (informational), not validation errors. Self-references are the only structural error.\n\n## Agent File Validation Strategy\n\nAgent frontmatter uses full YAML with sequences (e.g., `preloaded-skills` lists). The SKILL validator's subset YAML parser (`_validate_skills.py`) rejects sequences. Therefore, agent validation uses a **dedicated `parse_agent_frontmatter()` function** that extracts `name:` and `description:` scalar fields only \u2014 handling plain values, quoted strings, and block scalars (`|`/`>`). It does NOT reuse the SKILL YAML parser and does NOT attempt to parse sequences. This is a dedicated code path in the validator, shared with T13's similarity script (same extraction logic).\n\n## Bare-Reference Detection Strategy\n\nBare-ref detection (backtick-wrapped or bold-wrapped identifiers like `` `dotnet-testing-specialist` ``) uses an **allowlist of known IDs**: the union of skill directory names and agent file stems. Only tokens matching known IDs are flagged. This avoids false positives on .NET CLI tools (`dotnet-counters`, `dotnet-trace`, `dotnet-dump`, etc.) and other non-skill identifiers.\n\n## Budget Threshold Semantics\n\n- Acceptance criterion: `CURRENT_DESC_CHARS < 12,000` (strictly less than). All tasks must use this exact comparison.\n- `BUDGET_STATUS` in validator output reflects CURRENT chars only. T3 must update `_validate_skills.py` to decouple projected from budget status.\n- `PROJECTED_DESC_CHARS` is reported as a separate informational metric, not included in `BUDGET_STATUS`.\n- The validator's WARN condition triggers at `>= 12,000`, so reaching exactly 12,000 counts as WARN. Acceptance requires being below this threshold.\n\n## Quick commands\n\n```bash\n# Validate skills\n./scripts/validate-skills.sh\n\n# Validate marketplace\n./scripts/validate-marketplace.sh\n\n# Run similarity check\npython3 scripts/validate-similarity.py --repo-root .\n\n# Run routing tests (single case)\n./test.sh --agents claude --case-id foundation-routing\n```\n\n## Acceptance\n\n- [ ] All 130 SKILL.md descriptions follow canonical style guide from task 2\n- [ ] All cross-references in skills AND agent files use `[skill:name]` syntax (unified syntax for skills and agents)\n- [ ] All skills have explicit scope/out-of-scope sections\n- [ ] Validator enforces new routing-language quality checks (skills and agents via separate code paths)\n- [ ] Routing compliance report generates per-skill compliance data\n- [ ] Routing test assertions use definitive proof (Skill tool invocation, not text mentions)\n- [ ] Semantic similarity script detects pairwise description overlap using multi-signal composite score (stdlib-only)\n- [ ] Similarity CI gate prevents new high-overlap pairs (baseline + suppression list)\n- [ ] Similarity WARN pairs reduced vs pre-sweep baseline after T5-T9 sweeps\n- [ ] `./scripts/validate-skills.sh` passes with zero errors\n- [ ] `./scripts/validate-marketplace.sh` passes\n- [ ] CI gates updated: `STRICT_REFS=1` enabled, zero errors enforced, zero new warnings vs baseline\n- [ ] CONTRIBUTING-SKILLS.md, CLAUDE.md, CONTRIBUTING.md updated with canonical conventions (including similarity avoidance guidance)\n- [ ] CHANGELOG.md entry added\n- [ ] `CURRENT_DESC_CHARS < 12,000` (strictly below WARN threshold)\n\n## Dependency Graph\n\n```text\nT1 \u2192 T2 \u2192 {T3, T4, T13} \u2192 T5 \u2192 {T6, T7, T8, T9, T10} \u2192 T11 \u2192 T12\n```\n\nNote: T5 explicitly depends on T1 (ownership manifest), T3, T4, and T13.\n\nWaves:\n1. T1 (audit)\n2. T2 (spec)\n3. T3 + T4 + T13 (tooling + similarity, parallel)\n4. T5 (foundation + high-traffic)\n5. T6 + T7 + T8 + T9 + T10 (sweeps + agents, parallel)\n6. T11 (verification)\n7. T12 (docs + CI + rollout)\n\n## References\n\n- Agent Skills spec: https://agentskills.io/specification\n- Anthropic best practices: https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices\n- Existing validator: `scripts/_validate_skills.py`\n- Routing tests: `tests/agent-routing/check-skills.cs`\n- Prior art \u2014 similarity validation: KentoShimizu/sw-agent-skills `validate_skill_similarity.py` (difflib-based)\n- Prior art \u2014 multi-signal pattern similarity: nibzard/awesome-agentic-patterns (Jaccard + Levenshtein + category, 3.3K stars)\n- Prior art \u2014 tool boundary analysis: Abdulk084/tool-boundary-analyzer (TF-IDF + semantic, pip-installable)\n- Research \u2014 MCP tool description smells: arxiv 2602.14878v1 (97.1% have quality issues)\n- Research \u2014 tool deduplication threshold: arxiv 2511.01854 (0.82 cosine optimal for merging)\n"
  },
  "epic_id": "fn-53-skill-routing-language-hardening",
  "schema_version": 2,
  "tasks": [
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:21.495444Z",
        "depends_on": [],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.1",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.1.md",
        "status": "todo",
        "title": "Baseline Audit and Ownership Manifest",
        "updated_at": "2026-02-19T03:05:02.752269Z"
      },
      "id": "fn-53-skill-routing-language-hardening.1",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.1 Baseline Audit and Ownership Manifest\n\n## Description\nBuild a baseline inventory covering all 130 skills: description length, overlap risk score (pairwise textual similarity), cross-skill reference count/format, routing marker coverage (scope/out-of-scope/trigger sections), and routing hotspots from `tests/agent-routing/cases.json`. Produce an ownership manifest mapping each skill path to exactly one downstream editing task (T5-T10) with zero overlaps.\n\n**Size:** M\n**Files:**\n- `docs/skill-routing-audit-baseline.md` (new)\n- `docs/skill-routing-ownership-manifest.md` (new)\n- Read-only: all `skills/**/SKILL.md`, `tests/agent-routing/cases.json`, `agents/*.md`\n\n## Approach\n\n- Script-driven audit: iterate all SKILL.md files, extract frontmatter descriptions, count `[skill:]` refs, check for `## Scope`, `## Out of scope`, `## Trigger` sections\n- Compute preliminary pairwise textual overlap using simple word-set Jaccard (Jaccard on token sets with domain stopwords removed). This is a PRELIMINARY measure \u2014 T13 builds the production-quality multi-signal similarity script. T1 uses simple Jaccard to identify the top-N overlap hotspots for the audit report.\n- Identify the exact set of skills with zero routing markers via automated scan (known to be ~16 based on prior analysis)\n- Count bare-text references in `agents/*.md` files (currently ~50 across 8 agents)\n- Ownership assignment: divide 130 skills into T5 (foundation + high-traffic ~16), T6 (~30), T7 (~25), T8 (~25), T9 (~30 long tail), T10 (14 agent files). Each skill path appears in exactly one task.\n\n## Key context\n\n- Budget is currently at 12,345 chars (WARN at 12,000). Record per-skill char counts for budget tracking during sweeps.\n- Prior art: fn-29, fn-37 (cleanup sweep), fn-49 (compliance review), fn-51 (frontmatter) contain review rubrics and patterns. Reference relevant `.flow/specs/` entries but do not duplicate content.\n- Memory pitfall: \"Proposed replacement descriptions must have character counts verified\" -- use consistent `echo -n | wc -c` measurement.\n- T13 will build a proper multi-signal similarity script. T1 only needs simple Jaccard for the audit baseline to identify overlap hotspots.\n\n## Ownership manifest format\n\nFormat: Markdown table with columns `| Skill Path | Category | Assigned Task | Notes |`. Sorted by assigned task then path. T5-T9 filter their batch by the Assigned Task column. T10 is always the 14 agent files.\n\n## Acceptance\n- [ ] `docs/skill-routing-audit-baseline.md` exists with data for all 130 skills\n- [ ] Each skill entry includes: description length, overlap risk (top-3 most similar by Jaccard), cross-ref count, routing marker coverage (scope/out-of-scope/trigger: yes/no)\n- [ ] `docs/skill-routing-ownership-manifest.md` maps every skill path to exactly one task (T5-T10) using the specified table format\n- [ ] Zero overlaps in ownership (no skill path appears in two tasks)\n- [ ] Agent file bare-text reference count documented per agent\n- [ ] `./scripts/validate-skills.sh` still passes\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:36.959364Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.5"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.10",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.10.md",
        "status": "todo",
        "title": "Agent File Normalization",
        "updated_at": "2026-02-19T02:12:56.607566Z"
      },
      "id": "fn-53-skill-routing-language-hardening.10",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.10 Agent File Normalization\n\n## Description\nNormalize all 14 agent files (`agents/*.md`) to use canonical `[skill:]` cross-reference syntax. Currently 8 of 14 agents use bare-text references (~50 total). Also normalize agent description conventions per T2 style guide.\n\n**Size:** M\n**Files:**\n- All 14 `agents/*.md` files (edit)\n- Read-only: `docs/skill-routing-style-guide.md`\n\n## Approach\n\n- Convert all bare-text skill/agent references (backtick-wrapped, bold-wrapped) to `[skill:]` syntax\n- Agents confirmed to have bare refs: `dotnet-testing-specialist` (7), `dotnet-code-review-agent` (9), `dotnet-performance-analyst` (11), and 5 others\n- Agents already clean: `dotnet-architect`, `dotnet-blazor-specialist`, `dotnet-uno-specialist`, `dotnet-docs-generator`, `dotnet-security-reviewer`, `dotnet-maui-specialist`\n- Even \"clean\" agents must be scanned for edge-case bare refs (e.g., in Trigger Lexicon text, code comments, or reference URLs that happen to contain skill names)\n- Normalize agent description fields per style guide: no-WHEN-prefix, third-person declarative style (\"Analyzes X for Y\" not \"WHEN analyzing X\")\n- Verify all `[skill:]` references in agent files resolve to existing skill directories\n- After normalization, run the T3 agent validation (`--scan-agents` mode) to confirm zero bare-text refs remain\n\n## Key context\n\n- T3 adds automated agent file validation to `_validate_skills.py`. Use this to verify T10's work. Note: T3 reports agent bare-ref counts as informational (not errors) until T10 completes. After T10, T12 tightens the CI gate to enforce zero agent bare refs.\n- Memory pitfall: \"Cross-reference IDs must be canonical\" -- verify each ref against actual skill name: fields.\n- 5 agent descriptions currently use `WHEN` prefix. T2 style guide resolves: no WHEN prefix, third-person declarative.\n\n## Acceptance\n- [ ] All 14 agent files use `[skill:]` syntax for cross-references (zero bare-text refs, including in \"clean\" agents)\n- [ ] Agent descriptions follow style guide conventions (no WHEN prefix, third-person declarative)\n- [ ] All `[skill:]` references in agent files resolve to existing skill directories\n- [ ] T3 agent validation passes (zero `AGENT_BARE_REF_COUNT`)\n- [ ] `./scripts/validate-skills.sh` passes (agents not validated by this, but skills must not regress)\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:48.617944Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.6",
          "fn-53-skill-routing-language-hardening.7",
          "fn-53-skill-routing-language-hardening.8",
          "fn-53-skill-routing-language-hardening.9",
          "fn-53-skill-routing-language-hardening.10"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.11",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.11.md",
        "status": "todo",
        "title": "Content-Preservation Verification",
        "updated_at": "2026-02-19T03:17:45.132868Z"
      },
      "id": "fn-53-skill-routing-language-hardening.11",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.11 Content-Preservation Verification\n\n## Description\nMandatory verification that all intended content remains represented after normalization across T5-T10. Produce a content migration map with source-section to destination-section mapping. Run automated checks for dropped sections, broken references, self-links (errors) and cycles (report), and semantic similarity improvement.\n\n**Size:** M\n**Files:**\n- `docs/skill-content-migration-map.md` (new)\n- Read-only: all `skills/**/SKILL.md`, `agents/*.md`, sweep reports from T6-T9\n\n## Approach\n\n- Diff each SKILL.md against its pre-normalization state (git diff against the branch point)\n- Build migration map: for each modified skill, list sections before/after with content status (unchanged/reworded/moved/removed)\n- Run the T3 validator to check all cross-references resolve\n- Check for self-referential cross-links (skill referencing itself)\n- Verify no section was dropped without being moved elsewhere\n- Verify total description budget: `CURRENT_DESC_CHARS < 12,000` (strictly below WARN threshold)\n- **Run T13 similarity check** and compare against pre-sweep baseline: verify WARN pair count decreased or stayed the same, and no new ERROR pairs were introduced. Document before/after similarity summary.\n\n## Key context\n\n- Memory pitfall: \"Stale not-yet-landed references must be treated consistently\" -- check for `planned` status markers that should now be `implemented`\n- The `dotnet-advisor` catalog sections marked `planned`/`implemented` must be verified current\n- This is the quality gate before docs/CI updates in T12\n- T13's similarity baseline (`scripts/similarity-baseline.json`) provides the pre-sweep state. Re-run `python3 scripts/validate-similarity.py --repo-root .` and compare against this baseline.\n\n## Acceptance\n- [ ] `docs/skill-content-migration-map.md` covers all 130 skills with section-level before/after mapping\n- [ ] Zero dropped sections without documented migration target\n- [ ] Zero broken cross-references across skills and agents\n- [ ] Zero self-referential cross-links\n- [ ] `dotnet-advisor` catalog status markers are current\n- [ ] Total description budget: `CURRENT_DESC_CHARS < 12,000` (strictly less than WARN threshold)\n- [ ] Similarity improvement verified: WARN pair count <= pre-sweep baseline count. No new unsuppressed ERROR pairs.\n- [ ] Updated `scripts/similarity-baseline.json` with post-sweep pair data\n- [ ] `./scripts/validate-skills.sh` passes with zero errors and zero new warnings vs baseline\n- [ ] `./scripts/validate-marketplace.sh` passes\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:48.728718Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.11"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.12",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.12.md",
        "status": "todo",
        "title": "Contributor Guidance, CI Gates, and Rollout",
        "updated_at": "2026-02-19T03:06:59.625462Z"
      },
      "id": "fn-53-skill-routing-language-hardening.12",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.12 Contributor Guidance, CI Gates, and Rollout\n\n## Description\nUpdate all contributor-facing documentation to codify routing-language standards including similarity avoidance guidance. Update CI gates to enforce the new policy including similarity regression detection. Add CHANGELOG entry. Publish final compliance summary.\n\n**Size:** M\n**Files:**\n- `CONTRIBUTING-SKILLS.md` (edit -- final pass incorporating T2 style guide + T3 validator + T13 similarity + T11 verification results)\n- `CONTRIBUTING.md` (edit -- sync cross-reference syntax, description budget sections)\n- `CLAUDE.md` (edit -- update cross-ref example if T2 changed format, add routing-language key rule)\n- `.github/workflows/validate.yml` (edit -- enforce zero-new-warnings policy with baseline comparison, add similarity baseline comparison step)\n- `CHANGELOG.md` (edit -- add entry under `## [Unreleased]` / `### Changed`)\n- `docs/skill-routing-final-summary.md` (new -- compliance summary)\n\n## Approach\n\n- Update `CONTRIBUTING-SKILLS.md` Section 3 with final canonical rules, add reference to style guide, update pre-commit checklist with routing-language items. **Add new section on avoiding description overlap**: explain the similarity detection tool, how to run it locally, what thresholds mean, how to request a suppression if a pair is intentionally similar.\n- Update `CONTRIBUTING.md` quick-reference to match\n- Update `CLAUDE.md` cross-reference example to show canonical format\n- **Tighten agent bare-ref CI gate**: T3 reports `AGENT_BARE_REF_COUNT` and `AGENTSMD_BARE_REF_COUNT` as informational. After T10 normalizes agents, T12 makes these counts gating (fail on >0). Update `validate.yml` accordingly.\n- Add CI step to validate.yml: compare current warnings against `scripts/routing-warnings-baseline.json`, fail if increased\n- **Add CI step for similarity**: run `python3 scripts/validate-similarity.py --repo-root . --baseline scripts/similarity-baseline.json --suppressions scripts/similarity-suppressions.json` \u2014 fail if new pairs above WARN appear that are not in baseline or suppression list\n- CHANGELOG entry: \"Changed: Standardized routing language across all 130 skills and 14 agents for reliable skill discovery. Added semantic similarity detection to prevent description overlap.\"\n- Emit final compliance summary with aggregate stats including similarity improvement metrics\n\n## Key context\n\n- Follow Keep a Changelog format for CHANGELOG.md\n- `CLAUDE.md` is loaded into every Claude session -- keep additions concise\n- Memory pitfall: \"Skill/category counts in prose AND Mermaid diagrams must both be updated\" -- check for count references\n- The similarity detection script (`scripts/validate-similarity.py`) must be documented for contributors so they know to run it before submitting PRs with description changes\n\n## Acceptance\n- [ ] `CONTRIBUTING-SKILLS.md` fully reflects canonical routing-language rules and references style guide\n- [ ] `CONTRIBUTING-SKILLS.md` has section on avoiding description overlap (similarity tool usage, thresholds, suppression requests)\n- [ ] `CONTRIBUTING.md` quick-reference section synced with CONTRIBUTING-SKILLS.md\n- [ ] `CLAUDE.md` cross-reference example uses canonical format\n- [ ] `.github/workflows/validate.yml` enforces zero-new-warnings policy\n- [ ] `.github/workflows/validate.yml` gates on `AGENT_BARE_REF_COUNT == 0` and `AGENTSMD_BARE_REF_COUNT == 0` (tightened from informational)\n- [ ] `.github/workflows/validate.yml` has similarity regression check (baseline comparison)\n- [ ] `CHANGELOG.md` has entry for routing language standardization (including similarity detection)\n- [ ] `docs/skill-routing-final-summary.md` emitted with compliance stats (including similarity improvement metrics)\n- [ ] `./scripts/validate-skills.sh` passes\n- [ ] `./scripts/validate-marketplace.sh` passes\n- [ ] CI pipeline passes end-to-end\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T03:03:37.170955Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.2"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.13",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.13.md",
        "status": "todo",
        "title": "Semantic Similarity Overlap Detection Script",
        "updated_at": "2026-02-19T03:16:53.420985Z"
      },
      "id": "fn-53-skill-routing-language-hardening.13",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.13 Semantic Similarity Overlap Detection Script\n\n## Description\nBuild a standalone Python 3 script (`scripts/validate-similarity.py`) that computes pairwise semantic similarity between all skill AND agent descriptions using a multi-signal composite score. Zero external dependencies (stdlib only). CI-gatable with suppression list for known-acceptable pairs.\n\n**Size:** M\n**Files:**\n- `scripts/validate-similarity.py` (new \u2014 ~150-200 lines)\n- `scripts/_agent_frontmatter.py` (new \u2014 shared agent frontmatter parser, imported by both T13 and T3)\n- `scripts/similarity-suppressions.json` (new \u2014 known-acceptable pairs)\n- `scripts/similarity-baseline.json` (new \u2014 committed baseline of pairs above WARN)\n\n**File ownership boundary:** T13 delivers the standalone script and its data files. T13 does NOT edit `scripts/validate-skills.sh` or `.github/workflows/validate.yml` \u2014 those integrations are owned by T3.\n\n## Approach\n\n**Multi-signal composite score** (all Python stdlib):\n\nComposite formula (authoritative \u2014 matches epic spec):\n```\ncomposite = 0.4 * set_jaccard + 0.4 * seqmatcher + (0.15 if same_category else 0.0)\n```\n\n1. **Set Jaccard** (weight 0.4): Tokenize description \u2192 lowercase \u2192 strip domain stopwords \u2192 convert to `set(tokens)` (NOT Counter/multiset) \u2192 compute `|A \u2229 B| / |A \u222a B|`. Handle empty-after-stripping edge case (return 0.0, do not crash).\n\n2. **SequenceMatcher ratio** (weight 0.4): `difflib.SequenceMatcher(a=desc_a, b=desc_b).ratio()`. Operates on raw descriptions (NOT stopword-stripped) to capture character-level structural similarity.\n\n3. **Same-category adjustment** (+0.15 additive): If both items share the same category directory, add +0.15 directly to composite. This is a flat additive boost, not a weighted signal. Cross-category pairs get +0.0.\n\n**Domain stopwords** (authoritative list \u2014 matches epic spec, stripped before set Jaccard only):\n`dotnet`, `net`, `apps`, `building`, `designing`, `using`, `writing`, `implementing`, `adding`, `creating`, `configuring`, `managing`, `choosing`, `analyzing`, `working`, `patterns`, `for`\n\nThis is the initial starting point. During implementation, run against all 130 descriptions, identify terms appearing in >30% of descriptions, and add them. Changes to stopwords require regenerating baseline in the same PR.\n\n**Canonical pair identity**: Pairs identified by sorted tuple `(min(id_a, id_b), max(id_a, id_b))`. This ensures deterministic ordering in all output, baseline, and suppression files.\n\n**Thresholds** (calibrate against actual data \u2014 see Key context):\n- INFO: composite >= 0.40 (reported in JSON, not flagged)\n- WARN: composite >= 0.55 (needs review)\n- ERROR: composite >= 0.75 (must differentiate or suppress)\n\n**Suppression list** (`scripts/similarity-suppressions.json`):\n```json\n[\n  {\n    \"skill_a\": \"dotnet-ado-publish\",\n    \"skill_b\": \"dotnet-gha-publish\",\n    \"rationale\": \"Intentional parallel descriptions for different CI systems\"\n  }\n]\n```\nWhere `skill_a < skill_b` (sorted). Suppressed pairs:\n- Produce INFO-level output regardless of score\n- Are excluded from \"new WARN\" baseline regression detection\n- Are NOT counted in `PAIRS_ABOVE_WARN` or `PAIRS_ABOVE_ERROR`\n\n**Input scope**: Process all 130 skill descriptions from `skills/**/SKILL.md` AND all 14 agent descriptions from `agents/*.md`. Total: 144 items, 10,296 pairs.\n\n**Agent description extraction**: Use a minimal deterministic parser (dedicated function, NOT the SKILL subset YAML parser) that handles:\n- Plain scalar values: `description: Some text here`\n- Quoted strings (single and double): `description: \"Some text\"`\n- Block scalars (`|` and `>`): multi-line descriptions with proper indentation handling\nFactor this into a shared helper module (`scripts/_agent_frontmatter.py`) imported by both `validate-similarity.py` and T3's `_validate_skills.py`. It extracts only `name:` and `description:` \u2014 no sequences, flow constructs, or nested mappings.\n\n**Output**: JSON report to stdout with:\n- `pairs`: array of `{skill_a, skill_b, composite, jaccard, seqmatcher, same_category, level}` for all pairs above INFO, sorted by composite descending\n- `summary`: `{total_items, total_pairs, max_score, pairs_above_warn, pairs_above_error, suppressed_count, unsuppressed_errors, new_warns_vs_baseline}`\n- Stable CI output keys printed to stderr: `MAX_SIMILARITY_SCORE=<float>`, `PAIRS_ABOVE_WARN=<N>`, `PAIRS_ABOVE_ERROR=<N>`\n\n**Exit code semantics** (both conditions checked; either triggers exit 1):\n- Exit 0: No unsuppressed ERROR pairs AND no new WARNs vs baseline (when baseline provided)\n- Exit 1: Any unsuppressed ERROR pairs exist, OR any new WARN+ pairs not in baseline/suppressions\n- Exit 2: Script error (bad args, missing files)\nCounts for each condition emitted separately in summary.\n\n**Baseline file** (`scripts/similarity-baseline.json`):\n```json\n{\"version\": 1, \"pairs\": [[\"dotnet-foo\", \"dotnet-bar\"], ...]}\n```\nSchema-versioned. Pairs are sorted tuples above WARN threshold, sorted lexicographically. Deterministic output for stable git diffs.\n\n**CLI interface**:\n```bash\npython3 scripts/validate-similarity.py --repo-root . [--suppressions scripts/similarity-suppressions.json] [--warn-threshold 0.55] [--error-threshold 0.75] [--baseline scripts/similarity-baseline.json]\n```\n\n## Key context\n\n- **Actual similarity data** (from gap analysis live run): highest real pair is `dotnet-ado-publish` / `dotnet-gha-publish` at 0.71 SequenceMatcher. This is an intentional parallel pair. Next: `dotnet-data-access-strategy` / `dotnet-service-communication` at 0.62, `dotnet-gha-deploy` / `dotnet-gha-publish` at 0.61. Thresholds must account for these.\n- **Prior art**: KentoShimizu/sw-agent-skills `validate_skill_similarity.py` (difflib.SequenceMatcher, threshold 0.96, zero deps). Our approach adds set Jaccard and category awareness for better precision on short domain-specific text.\n- **No external deps**: Validator is stdlib-only. Similarity script follows same constraint. Only use: `difflib`, `collections`, `re`, `argparse`, `json`, `sys`, `pathlib`, `math`.\n- **Performance**: 10,296 pairs with tokenization + 2 similarity computations each. Typically <2 seconds on modern hardware; acceptance gate is <5 seconds.\n- **File ownership**: T13 does NOT edit `validate-skills.sh` or `validate.yml`. T3 owns those integrations.\n- Memory pitfall: \"Proposed replacement descriptions must have character counts verified\" \u2014 similarity script must use consistent tokenization across runs for deterministic scores.\n\n## Acceptance\n- [ ] `scripts/validate-similarity.py` exists, runs with `python3`, zero external dependencies\n- [ ] Composite formula matches epic spec: `0.4 * set_jaccard + 0.4 * seqmatcher + (0.15 if same_category else 0.0)`\n- [ ] Set Jaccard uses `set(tokens)` (NOT Counter/multiset)\n- [ ] Domain stopwords match epic spec authoritative list, stripped before Jaccard only\n- [ ] Processes both skill descriptions (130) AND agent descriptions (14) \u2014 144 items total\n- [ ] Agent descriptions extracted via dedicated `parse_agent_frontmatter()` handling plain scalars, quoted strings, and block scalars\n- [ ] Canonical pair identity: sorted tuple `(min(id_a, id_b), max(id_a, id_b))`\n- [ ] JSON output with per-pair detail + summary stats, sorted by composite descending\n- [ ] Stable CI output keys on stderr: `MAX_SIMILARITY_SCORE`, `PAIRS_ABOVE_WARN`, `PAIRS_ABOVE_ERROR`\n- [ ] Suppression list (`scripts/similarity-suppressions.json`) with `skill_a < skill_b` ordering; at least `dotnet-ado-publish` / `dotnet-gha-publish` pair\n- [ ] Suppressed pairs produce INFO, excluded from WARN/ERROR counts and baseline regression\n- [ ] Baseline mode (`--baseline`) detects NEW pairs above WARN not in baseline or suppression list\n- [ ] `scripts/similarity-baseline.json` committed with `{version: 1, pairs: [...]}` schema, sorted output\n- [ ] Exit code 0 when no unsuppressed ERRORs AND no new WARNs vs baseline; exit 1 otherwise; exit 2 on script error\n- [ ] Thresholds calibrated against actual data: zero false-positive ERRORs on current descriptions (after suppression)\n- [ ] Empty/missing descriptions handled without crash (return 0.0 for pair, skip from results)\n- [ ] Deterministic output: same input \u2192 same JSON output\n- [ ] Performance: completes in < 5 seconds for 144 items\n- [ ] Does NOT edit `validate-skills.sh` or `validate.yml` (T3 owns those)\n- [ ] `./scripts/validate-skills.sh` still passes\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:27.927166Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.1"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.2",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.2.md",
        "status": "todo",
        "title": "Canonical Routing Language Spec",
        "updated_at": "2026-02-19T02:46:33.861867Z"
      },
      "id": "fn-53-skill-routing-language-hardening.2",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.2 Canonical Routing Language Spec\n\n## Description\nDefine canonical rules for skill routing language as a style guide document. Cover: classifier-style descriptions (\u2264120 chars, front-loaded action verb, what+when+triggers), explicit scope/out-of-scope section format, normalized cross-reference language (`See [skill:x] for Y` where Y is specific), router precedence language (baseline-first loading of `dotnet-csharp-coding-standards`), and agent file reference conventions.\n\n**Size:** M\n**Files:**\n- `docs/skill-routing-style-guide.md` (new)\n- `CONTRIBUTING-SKILLS.md` (update Section 3 \"Writing Effective Descriptions\")\n\n## Approach\n\n- Codify the present-participle description style already dominant across 130 skills (e.g., \"Building...\", \"Designing...\", \"Using...\")\n- Define mandatory sections: every skill must have `## Scope` and `## Out of scope` with `[skill:]` attribution\n- Define cross-reference format: `See [skill:x] for Y.` where Y is a specific topic (not \"more details\")\n- Define unified reference syntax: `[skill:name]` refers to any routable artifact (skills OR agents). The validator resolves against the union of skill directory names + agent file stems. Explicitly state this in the style guide with examples for both skills and agents.\n- Include positive/negative examples table (follow pattern at `CONTRIBUTING-SKILLS.md:126-131`)\n- Include migration checklist for converting existing descriptions\n- Address CI strict mode: recommend setting `STRICT_REFS=1` in `validate.yml` (broken refs = errors). Local development keeps lenient default.\n\n## Self-references and cycles\n\n- Self-references (skill referencing itself) are always an error.\n- Bidirectional references (e.g., `dotnet-advisor` \u2194 `dotnet-version-detection`) are legitimate for hub skills. Cycle detection produces an informational report, not validation errors.\n- Style guide must explicitly state these rules with examples.\n\n## WHEN-prefix resolution\n\nAgent `description` fields follow the same no-WHEN-prefix rule as skills. Agent descriptions use third-person declarative style: \"Analyzes X for Y\" not \"WHEN analyzing X\". This aligns agents and skills under one convention. The style guide must state this explicitly with before/after examples.\n\n## CONTRIBUTING-SKILLS.md scope boundary\n\nT2 writes the initial canonical rules into Section 3. T12 will add enforcement-specific guidance (validator flags, baseline policy, CI gate configuration) after verification is complete. T2 does NOT cover CI/validator usage patterns \u2014 only the style rules themselves.\n\n## Budget threshold semantics\n\nStyle guide must clarify: acceptance criterion is `CURRENT_DESC_CHARS < 12,000` (strictly less than). The validator WARN triggers at `>= 12,000`, so exactly 12,000 still yields WARN. PROJECTED_DESC_CHARS is a separate informational metric, not part of BUDGET_STATUS.\n\n## Key context\n\n- Anthropic best practices: \"description must describe what the skill does AND when to use it\" -- third person, no filler\n- Research: assertive cues create 7x bias, position bias 80.2% for first tool. Descriptions must be factual.\n- Budget constraint: 120 chars max per description, 12K warn threshold aggregate. Style guide must emphasize budget-neutral changes.\n- 5 agent descriptions currently use `WHEN` prefix. Style guide resolves: no WHEN prefix for agents or skills.\n\n## Acceptance\n- [ ] `docs/skill-routing-style-guide.md` exists with: description formula, scope/out-of-scope format, cross-reference format (unified `[skill:]` for skills and agents), precedence language, positive/negative examples table, migration checklist\n- [ ] Style guide explicitly documents unified `[skill:]` syntax covering both skills and agents, with examples\n- [ ] Style guide explicitly documents self-reference (error) vs cycle (informational report) policy\n- [ ] Style guide clarifies budget threshold: `CURRENT_DESC_CHARS < 12,000` and PROJECTED as informational only\n- [ ] `CONTRIBUTING-SKILLS.md` Section 3 updated to reference style guide and incorporate canonical rules (style rules only; enforcement guidance deferred to T12)\n- [ ] Style guide explicitly resolves WHEN-prefix: no-WHEN-prefix for both skills and agents, with third-person declarative style and before/after examples\n- [ ] Style guide addresses CI strict mode recommendation (`STRICT_REFS=1`)\n- [ ] `./scripts/validate-skills.sh` still passes\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:28.033591Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.2"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.3",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.3.md",
        "status": "todo",
        "title": "Validator and Compliance Report Hardening",
        "updated_at": "2026-02-19T03:17:45.280312Z"
      },
      "id": "fn-53-skill-routing-language-hardening.3",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.3 Validator and Compliance Report Hardening\n\n## Description\nExtend `_validate_skills.py` with new routing-language quality checks for SKILL.md files AND agent files (via separate code paths). Create a standalone compliance report script. Define CI policy: zero errors, zero new warnings vs committed baseline file. **Own the integration of T13's similarity script into `validate-skills.sh` and CI workflow.**\n\n**Size:** M\n**Files:**\n- `scripts/_validate_skills.py` (edit)\n- `scripts/validate-skills.sh` (edit \u2014 T3 is the sole owner of this file. Update header docs for new output keys, add invocation of T13's `validate-similarity.py`, report similarity output keys)\n- `scripts/skill-routing-report.py` (new \u2014 compliance report)\n- `scripts/routing-warnings-baseline.json` (new \u2014 committed baseline)\n- `.github/workflows/validate.yml` (edit \u2014 set `STRICT_REFS=1`, add new output key parsing, add similarity check step invoking T13's script)\n\n## Approach\n\n- New validator checks for SKILL.md files:\n  - Scope section presence (`## Scope` header required)\n  - Out-of-scope section presence (`## Out of scope` header required)\n  - Out-of-scope attribution format (each out-of-scope item should reference owning skill via `[skill:]`)\n  - Self-referential cross-link detection (skill referencing itself) \u2014 **error**\n  - Cross-reference cycle detection (post-processing phase) \u2014 **informational report only, NOT an error** (see implementation note below)\n- New validator checks for agent files (dedicated code path \u2014 NOT reusing the SKILL YAML parser):\n  - **Dedicated `parse_agent_frontmatter()` function** that extracts `name:` and `description:` scalar fields from agent frontmatter, handling plain values, quoted strings, and block scalars. Does NOT attempt sequences.\n  - Extract `[skill:]` refs from all `agents/*.md` and validate against the union of `valid_skill_dirs` + agent file stems\n  - Detect bare-text skill/agent references using an **allowlist of known IDs**. Only flag tokens matching known IDs. This avoids false positives on .NET CLI tools.\n  - New stable output key: `AGENT_BARE_REF_COUNT`\n- New validator check for `AGENTS.md`:\n  - Detect bare `dotnet-[a-z-]+` names matching known skill/agent IDs not wrapped in `[skill:]` syntax\n  - New stable output key: `AGENTSMD_BARE_REF_COUNT`\n- Cross-reference validation resolves `[skill:]` refs against the **union** of skill directory names + agent file stems\n- **Budget status fix**: Update `_validate_skills.py` to compute `BUDGET_STATUS` from `CURRENT_DESC_CHARS` only. `PROJECTED_DESC_CHARS` is still printed but does NOT influence `BUDGET_STATUS`. This aligns with the epic spec's rule: `CURRENT_DESC_CHARS < 12,000`.\n- **Docstring update**: Re-number and extend the module docstring (lines 3-17) to list all new checks consistently. Fix existing \"6.\" duplication.\n- New stable CI-parseable output keys: `MISSING_SCOPE_COUNT`, `MISSING_OOS_COUNT`, `SELF_REF_COUNT`, `AGENT_BARE_REF_COUNT`, `AGENTSMD_BARE_REF_COUNT`\n- Compliance report script: reads all SKILL.md files, outputs JSON with per-skill compliance metrics\n- Baseline file: JSON with current warning counts, committed to repo. CI compares against baseline.\n- CI strict mode: set `STRICT_REFS=1` in `validate.yml`\n- **Similarity integration** (T3 owns this): Update `validate-skills.sh` to invoke `scripts/validate-similarity.py` (built by T13) and report its output keys. Update `.github/workflows/validate.yml` to parse similarity keys and fail if similarity check fails. T13 must complete before T3 can test this integration, but T3 can implement the wiring with the documented interface.\n\n## Cycle detection implementation\n\nAfter all files are processed, build a directed cross-reference graph. Run cycle detection (DFS). Report cycles as informational output (not errors). Only self-references are errors.\n\n## Agent file validation \u2014 separate code path\n\nUse `parse_agent_frontmatter()` that handles plain scalars, quoted strings, and block scalars for `name:` and `description:` only. Factor into a shared helper module (`scripts/_agent_frontmatter.py`) imported by both `_validate_skills.py` and T13's `validate-similarity.py`.\n\n## Key context\n\n- Current validator checks 8 things. New checks extend this list.\n- Follow existing patterns: `FILLER_PHRASES` list, new checks should follow same structure.\n- Agent files are currently NOT processed by `_validate_skills.py`. This task adds that capability.\n- Memory pitfall: \"Hand-authored YAML configuration files require CI validation rules\"\n- T13 builds `scripts/validate-similarity.py`. T3 wires it into `validate-skills.sh` and `validate.yml`.\n\n## Agent validation gating strategy\n\nAgent bare-ref counts (`AGENT_BARE_REF_COUNT`, `AGENTSMD_BARE_REF_COUNT`) are **reported as informational output** by T3's validator, NOT as validation errors. This prevents a deadlock: T3 (wave 3) adds agent scanning before T10 (wave 5) normalizes agent files. The CI gate for agent bare-ref counts becomes mandatory only after T10 completes \u2014 T12 tightens the gate as part of final CI enforcement.\n\n## Acceptance\n- [ ] `_validate_skills.py` has new checks: scope presence, out-of-scope presence, out-of-scope attribution, self-referential refs (error), cycle detection (informational report, NOT error)\n- [ ] `_validate_skills.py` module docstring updated and consistently numbered for all checks (old + new)\n- [ ] `_validate_skills.py` computes `BUDGET_STATUS` from `CURRENT_DESC_CHARS` only (projected is informational, not part of status)\n- [ ] `_validate_skills.py` has agent file scanning via dedicated `parse_agent_frontmatter()` (handles plain, quoted, block scalars; NOT subset YAML parser)\n- [ ] Agent bare-ref detection uses allowlist of known skill/agent IDs\n- [ ] Cross-reference validation resolves against union of skill IDs + agent IDs\n- [ ] `_validate_skills.py` has AGENTS.md scanning: detects bare known IDs not in `[skill:]` syntax\n- [ ] New stable output keys documented in `validate-skills.sh` header (including `AGENT_BARE_REF_COUNT`, `AGENTSMD_BARE_REF_COUNT`)\n- [ ] `scripts/skill-routing-report.py` generates per-skill compliance JSON (includes cycle report)\n- [ ] `scripts/routing-warnings-baseline.json` committed with current counts\n- [ ] `STRICT_REFS=1` set in `.github/workflows/validate.yml`\n- [ ] `validate-skills.sh` invokes T13's `scripts/validate-similarity.py` and reports similarity output keys (`MAX_SIMILARITY_SCORE`, `PAIRS_ABOVE_WARN`, `PAIRS_ABOVE_ERROR`)\n- [ ] `.github/workflows/validate.yml` parses all new output keys (validator + similarity) and fails on similarity check failure\n- [ ] `./scripts/validate-skills.sh` passes\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:28.171416Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.2"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.4",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.4.md",
        "status": "todo",
        "title": "Routing Test Assertion Hardening",
        "updated_at": "2026-02-19T02:47:26.637910Z"
      },
      "id": "fn-53-skill-routing-language-hardening.4",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.4 Routing Test Assertion Hardening\n\n## Description\nTighten routing test evidence patterns in `check-skills.cs` to require skill-specific proof rather than generic matches. Update `cases.json` evidence patterns. Update `docs/agent-routing-tests.md` with refined evidence hierarchy.\n\n**Size:** M\n**Files:**\n- `tests/agent-routing/check-skills.cs` (edit)\n- `tests/agent-routing/cases.json` (edit)\n- `docs/agent-routing-tests.md` (edit)\n\n## Approach\n\n- **Existing hardening already in place:** The runner already extracts `\"Launching skill:\"` and `{\"skill\":\"...\"}` evidence tokens (`check-skills.cs:75-77, 854-891`) and avoids requiring SKILL.md reads for Claude (`check-skills.cs:800-819`). Do not duplicate this.\n- **What's actually missing:** Non-Claude agents (Codex, Copilot) use file-evidence tokens. Current patterns accept generic `\"SKILL.md\"` matches that could be incidental. Tighten to require `\"<expectedSkill>/SKILL.md\"` (skill-specific file path).\n- Update `cases.json` evidence patterns to use skill-specific file paths for non-Claude evidence\n- Keep Claude evidence patterns unchanged (already use definitive `Launching skill:` / `{\"skill\":\"...\"}` tokens)\n- Update `docs/agent-routing-tests.md` \"Evidence currently gates on\" section with refined evidence hierarchy distinguishing Claude vs non-Claude evidence\n- Test against existing 14 cases to ensure no false negatives from stricter evidence\n\n## Verification strategy\n\nT4's primary job is hardening the assertion logic and evidence patterns. For local validation during development, use `--agents claude` (single agent) to verify the 14 cases pass with hardened assertions. Full multi-agent verification (claude + codex + copilot, 42 invocations) is deferred to T11's integration check. This avoids the 63-minute serial test run during T4 development.\n\n## Key context\n\n- Current evidence patterns like `\"dotnet-xunit\"` and `\"SKILL.md\"` match incidental mentions, not just skill invocations\n- Claude target evidence: `\"Launching skill: dotnet-xunit\"` or `\"skill\":\"dotnet-xunit\"` \u2014 already implemented\n- Non-Claude target evidence: `\"dotnet-xunit/SKILL.md\"` (skill-specific file path) \u2014 needs tightening\n- Only 14 test cases exist covering ~10% of 130 skills. This task hardens assertions, not coverage.\n\n## Acceptance\n- [ ] Non-Claude evidence patterns in `cases.json` use skill-specific file paths (not generic `\"SKILL.md\"`)\n- [ ] Claude evidence patterns remain unchanged (already use definitive proof)\n- [ ] `check-skills.cs` assertion logic handles skill-specific file-evidence tokens correctly\n- [ ] `docs/agent-routing-tests.md` updated with evidence hierarchy (Claude vs non-Claude)\n- [ ] All 14 existing test cases pass with hardened assertions (verified with `--agents claude` for local validation)\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:36.422658Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.3",
          "fn-53-skill-routing-language-hardening.4",
          "fn-53-skill-routing-language-hardening.13",
          "fn-53-skill-routing-language-hardening.1"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.5",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.5.md",
        "status": "todo",
        "title": "Normalize Foundation and High-Traffic Skills",
        "updated_at": "2026-02-19T03:14:13.649001Z"
      },
      "id": "fn-53-skill-routing-language-hardening.5",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.5 Normalize Foundation and High-Traffic Skills\n\n## Description\nApply canonical routing language (from T2 style guide) to the foundation skills and all high-traffic skills listed in `tests/agent-routing/cases.json`. Normalize `AGENTS.md` cross-references. These are the most-routed skills and set the pattern for subsequent sweeps.\n\n**Size:** M (heavy \u2014 ~16 skills plus AGENTS.md, but templated per-skill work)\n**Files:**\n- `skills/foundation/dotnet-advisor/SKILL.md` (edit)\n- `skills/foundation/dotnet-version-detection/SKILL.md` (edit)\n- `AGENTS.md` (edit -- normalize existing cross-references to `[skill:]` syntax)\n- ~14 additional skills referenced in `tests/agent-routing/cases.json` (edit)\n- Read-only: `docs/skill-routing-ownership-manifest.md` (task list), `docs/skill-routing-style-guide.md` (rules)\n\n## Approach\n\n- Read ownership manifest to confirm which skills belong to this task (T5 batch only)\n- Apply style guide rules: scope/out-of-scope sections, cross-ref format, description normalization\n- For `dotnet-advisor`: add routing markers (currently zero markers), update specialist routing section to use `[skill:]` syntax instead of bold text\n- For `AGENTS.md`: normalize any bare-text skill/agent names in existing content to `[skill:]` syntax. Note: `AGENTS.md` contains plugin instructions and conventions (File Structure, Validation Commands, etc.) \u2014 it does NOT have a routing index or delegation patterns table. The delegation flow content lives in `README.md` which is out of scope for this epic.\n- **Run similarity check** before AND after edits: `python3 scripts/validate-similarity.py --repo-root .` \u2014 use the T13 similarity report to identify high-overlap pairs in this batch and prioritize description differentiation. Confirm no new WARN pairs introduced.\n- Run `./scripts/validate-skills.sh` after each batch of changes\n- Track budget delta: record before/after description char counts\n\n## Budget reduction target\n\nT5 owns the primary budget reduction. Current total: 12,345 chars. Target: net reduction of \u2265350 chars from this batch. Foundation skills like `dotnet-advisor` (currently the most verbose description) are the primary reduction source. Subsequent sweep tasks (T6-T9) must stay budget-neutral or budget-negative but are not expected to achieve significant reductions. Cumulative budget across T5-T9 completions must reach `CURRENT_DESC_CHARS < 12,000`.\n\n## Catalog status markers\n\nDo not change catalog status markers (`implemented`/`planned`) in `dotnet-advisor/SKILL.md` during normalization. T11 will audit their accuracy as part of content-preservation verification.\n\n## Key context\n\n- `dotnet-advisor` is the central router. Its SKILL.md has specialist references using `**name**` bold format (lines 334-338). Convert to `[skill:]`.\n- `AGENTS.md` is a concise plugin instructions file (121 lines). Cross-Reference Syntax section (lines 54-62) already documents `[skill:]` convention. Scan for any bare-text violations in the rest of the file.\n- The 14 cases.json skills are the highest-traffic paths. Getting these right first ensures routing test reliability.\n- Memory pitfall: \"Cross-reference IDs must be canonical\" -- verify each ref against actual `SKILL.md` name: fields.\n- T13's similarity report highlights the top overlap pairs. Use this data to prioritize which descriptions to differentiate most aggressively.\n\n## Acceptance\n- [ ] Foundation skills (`dotnet-advisor`, `dotnet-version-detection`) have scope/out-of-scope sections and canonical descriptions\n- [ ] `dotnet-advisor` specialist routing uses `[skill:]` syntax (no bold-text agent names)\n- [ ] `AGENTS.md` cross-references normalized to `[skill:]` syntax where applicable\n- [ ] All ~14 high-traffic skills from `cases.json` normalized per style guide\n- [ ] All cross-references use canonical `[skill:]` syntax (unified for skills and agents)\n- [ ] Budget delta documented: net reduction of \u2265350 chars from this batch. Total chars before vs after recorded. Target: `CURRENT_DESC_CHARS < 12,000`.\n- [ ] **Similarity check**: Run similarity before and after this batch (same branch, same suppressions). `pairs_above_warn` does not increase and `unsuppressed_errors == 0`.\n- [ ] `./scripts/validate-skills.sh` passes\n- [ ] Existing routing test cases still pass\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:36.529726Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.5"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.6",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.6.md",
        "status": "todo",
        "title": "Category Sweep - Core, Architecture, Performance, Build",
        "updated_at": "2026-02-19T03:07:15.642433Z"
      },
      "id": "fn-53-skill-routing-language-hardening.6",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.6 Category Sweep - Core, Architecture, Performance, Build\n\n## Description\nApply canonical routing language to skills assigned to this batch by the T1 ownership manifest. Categories: core-csharp, architecture, performance-benchmarking, msbuild-build. No overlap with T7/T8/T9.\n\n**Size:** M\n**Files:** Subset from `docs/skill-routing-ownership-manifest.md` (~30 skills)\n\n## Approach\n\n- Read ownership manifest to get exact skill list for this task\n- For each skill: normalize description (\u2264120 chars, front-loaded verb, what+when), add/update `## Scope` and `## Out of scope` sections, convert all cross-refs to `[skill:]` format\n- Track budget delta per skill\n- Run validator after completing batch\n- Emit `docs/skill-routing-sweep-core-arch-perf-build.md` with before/after stats\n\n## Key context\n\n- Budget-neutral: if a description grows, shorten another in the same batch\n- Follow the T2 style guide exactly -- no creative reinterpretation\n- Memory pitfall: \"Every skill section MUST use explicit `##` headers\" -- not inline bold labels\n## Acceptance\n- [ ] All assigned skills have scope/out-of-scope sections\n- [ ] All descriptions follow canonical style (\u2264120 chars, front-loaded verb)\n- [ ] All cross-references use `[skill:]` syntax\n- [ ] `docs/skill-routing-sweep-core-arch-perf-build.md` emitted with before/after stats\n- [ ] Budget delta documented: no net increase\n- [ ] **Similarity check**: Run similarity before and after this batch (same branch, same suppressions). `pairs_above_warn` does not increase and `unsuppressed_errors == 0`.\n- [ ] `./scripts/validate-skills.sh` passes\n- [ ] No skills from T7/T8/T9/T10 batches were edited\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:36.637513Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.5"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.7",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.7.md",
        "status": "todo",
        "title": "Category Sweep - API, Security, Testing, CI",
        "updated_at": "2026-02-19T03:07:15.763374Z"
      },
      "id": "fn-53-skill-routing-language-hardening.7",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.7 Category Sweep - API, Security, Testing, CI\n\n## Description\nApply canonical routing language to skills assigned to this batch: api-development, security, testing, ci-cd categories. No overlap with T6/T8/T9.\n\n**Size:** M\n**Files:** Subset from `docs/skill-routing-ownership-manifest.md` (~25 skills)\n\n## Approach\n\n- Same workflow as T6 but for API/Security/Testing/CI categories\n- Must include the two fn-36 skills (`dotnet-library-api-compat`, `dotnet-api-surface-validation`)\n- Emit `docs/skill-routing-sweep-api-security-testing-ci.md`\n\n## Key context\n\n- fn-36 added two new API skills that must be included in 100% coverage\n- Testing skills have significant overlap risk (e.g., `dotnet-testing-strategy` vs `dotnet-xunit` vs `dotnet-integration-testing`). Pay extra attention to scope boundaries.\n## Acceptance\n- [ ] All assigned skills have scope/out-of-scope sections\n- [ ] All descriptions follow canonical style\n- [ ] All cross-references use `[skill:]` syntax\n- [ ] fn-36 skills included\n- [ ] `docs/skill-routing-sweep-api-security-testing-ci.md` emitted\n- [ ] Budget delta documented: no net increase\n- [ ] **Similarity check**: Run similarity before and after this batch (same branch, same suppressions). `pairs_above_warn` does not increase and `unsuppressed_errors == 0`.\n- [ ] `./scripts/validate-skills.sh` passes\n- [ ] No skills from T6/T8/T9/T10 batches were edited\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:36.744800Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.5"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.8",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.8.md",
        "status": "todo",
        "title": "Category Sweep - UI, NativeAOT, CLI, TUI",
        "updated_at": "2026-02-19T03:07:15.887859Z"
      },
      "id": "fn-53-skill-routing-language-hardening.8",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.8 Category Sweep - UI, NativeAOT, CLI, TUI\n\n## Description\nApply canonical routing language to skills assigned to this batch: blazor, uno-platform, maui, desktop-frameworks, native-aot-trimming, cli-tools, tui categories. No overlap with T6/T7/T9.\n\n**Size:** M\n**Files:** Subset from `docs/skill-routing-ownership-manifest.md` (~25 skills)\n\n## Approach\n\n- Same workflow as T6 but for UI/NativeAOT/CLI/TUI categories\n- Align platform classifier wording across frameworks (Blazor vs MAUI vs Uno vs WinUI)\n- Emit `docs/skill-routing-sweep-ui-nativeaot-cli-tui.md`\n\n## Key context\n\n- UI framework skills need clear scope boundaries: \"Blazor components\" vs \"MAUI mobile\" vs \"Uno cross-platform\" vs \"WinUI desktop\"\n- AOT skills overlap with several framework skills. Scope boundaries are critical.\n## Acceptance\n- [ ] All assigned skills have scope/out-of-scope sections\n- [ ] All descriptions follow canonical style\n- [ ] Platform classifier wording is consistent across framework families\n- [ ] `docs/skill-routing-sweep-ui-nativeaot-cli-tui.md` emitted\n- [ ] Budget delta documented: no net increase\n- [ ] **Similarity check**: Run similarity before and after this batch (same branch, same suppressions). `pairs_above_warn` does not increase and `unsuppressed_errors == 0`.\n- [ ] `./scripts/validate-skills.sh` passes\n- [ ] No skills from T6/T7/T9/T10 batches were edited\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T01:48:36.851901Z",
        "depends_on": [
          "fn-53-skill-routing-language-hardening.5"
        ],
        "epic": "fn-53-skill-routing-language-hardening",
        "id": "fn-53-skill-routing-language-hardening.9",
        "priority": null,
        "spec_path": ".flow/tasks/fn-53-skill-routing-language-hardening.9.md",
        "status": "todo",
        "title": "Category Sweep - Long Tail",
        "updated_at": "2026-02-19T03:07:16.008589Z"
      },
      "id": "fn-53-skill-routing-language-hardening.9",
      "runtime": null,
      "spec": "# fn-53-skill-routing-language-hardening.9 Category Sweep - Long Tail\n\n## Description\nNormalize all remaining skills not covered by T5-T8. This is the long-tail batch with a concrete, closed-form list from the ownership manifest.\n\n**Size:** M\n**Files:** Residual skill list from `docs/skill-routing-ownership-manifest.md` (~30 skills across remaining categories: serialization, documentation, localization, packaging, data-access, messaging, observability, domain-modeling, etc.)\n\n## Approach\n\n- Same workflow as T6 but for residual skills\n- List must be explicit and complete -- no implicit \"remaining\" edits\n- Emit `docs/skill-routing-sweep-long-tail.md`\n- After completion, verify ownership manifest shows 100% coverage (every skill assigned and completed)\n\n## Key context\n\n- These skills are lower-traffic but still need consistent routing language\n- Some may have unique scope challenges (e.g., `dotnet-domain-modeling` vs `dotnet-efcore-architecture`)\n## Acceptance\n- [ ] All assigned skills have scope/out-of-scope sections\n- [ ] All descriptions follow canonical style\n- [ ] `docs/skill-routing-sweep-long-tail.md` emitted\n- [ ] Ownership manifest shows 100% of skills assigned and completed (across T5-T9)\n- [ ] Budget delta documented: no net increase\n- [ ] **Similarity check**: Run similarity before and after this batch (same branch, same suppressions). `pairs_above_warn` does not increase and `unsuppressed_errors == 0`.\n- [ ] `./scripts/validate-skills.sh` passes\n- [ ] No skills from T6/T7/T8/T10 batches were edited\n## Done summary\nTBD\n\n## Evidence\n- Commits:\n- Tests:\n- PRs:\n"
    }
  ]
}
