{
  "created_at": "2026-02-20T07:44:32.819440Z",
  "epic": {
    "data": {
      "branch_name": "fn-54-agent-routing-harness-determinism-and",
      "completion_review_status": "unknown",
      "completion_reviewed_at": null,
      "created_at": "2026-02-19T23:00:22.408925Z",
      "default_impl": null,
      "default_review": null,
      "default_sync": null,
      "depends_on_epics": [
        "fn-53-skill-routing-language-hardening"
      ],
      "id": "fn-54-agent-routing-harness-determinism-and",
      "next_task": 1,
      "plan_review_status": "ship",
      "plan_reviewed_at": "2026-02-20T00:31:51.567376Z",
      "spec_path": ".flow/specs/fn-54-agent-routing-harness-determinism-and.md",
      "status": "open",
      "title": "Agent Routing Harness Determinism and Observability",
      "updated_at": "2026-02-20T00:31:51.567750Z"
    },
    "spec": "# Agent Routing Harness Determinism and Observability\n\n## Overview\n\nHarden the agent routing test harness (`test.sh` + `check-skills.cs`) with lifecycle telemetry, evidence-tier gating, nondeterminism-aware evaluation semantics, and cross-provider regression guardrails. Builds on fn-53 (Skill Routing Language Hardening).\n\n**PRD:** `.flow/specs/prd-routing-reliability-and-skill-invocation.md`\n**PRD amendment:** `parse` failure category deferred to future structured-output epic. PRD to be updated with rationale: current runner performs substring matching, not JSON parsing \u2014 no meaningful parse operation exists to classify. The `timeout`, `transport`, and `assertion` categories cover all current failure modes.\n\n## Scope\n\n- Add stable run IDs (batch + unit) and lifecycle progress output per prompt-agent unit\n- Isolate ALL artifacts (results.json + tool-use-proof.log) per batch run under `<artifacts-root>/<batch_run_id>/`\n- Set sensible MAX_CONCURRENCY default (4) with env var override\n- Reshape evidence evaluation to per-token best-hit model with tier/source tracking\n- Implement `ComputeTier(agent, token, line, score)` with explicit regex + capture strategy per provider\n- Introduce typed evidence requirements and make `expected_skill` implicitly Tier 1\n- Prevent log_fallback from satisfying Tier 1; disable log_fallback pass-promotion when parallel\n- Optimize log scanning: per-agent-per-batch snapshot, gated behind flag when parallel\n- Extend `CaseDefinition` with `optional_skills[]`, `disallowed_skills[]` (tier-gated), `provider_aliases{}`\n- Add mismatch classification (missing_required, disallowed_hit, optional_only, mixed) + failure categories (timeout, transport, assertion)\n- Convert CI to GHA strategy matrix with base-branch-head baseline comparison and mechanically enforceable regression gate\n- Update operator docs\n\n## Design decisions\n\n- **Run ID scheme:** `batch_run_id` (per RunAsync) + `unit_run_id` (per work item). T1 owns run ID generation, JSON fields, and lifecycle progress. T4 consumes `batch_run_id` for artifact directory naming, `--artifacts-root`, `ARTIFACT_DIR` emission, and default proof log path.\n- **Artifact isolation \u2014 batch-level only, always written:** Runner always writes `<artifacts-root>/<batch_run_id>/results.json` and `<artifacts-root>/<batch_run_id>/tool-use-proof.log` regardless of `--output` flag. `--output` is preserved for backward compat (writes an additional copy) but the batch dir copy is unconditional. This means CI never needs to pass `--output` \u2014 the batch dir is the single source of truth. No per-unit subdirectories \u2014 two files per batch is sufficient for current debuggability. Per-unit directories deferred until concrete per-unit artifacts exist. JSON is also written to stdout as before (convenience copy). `test.sh` hardcoded `PROOF_LOG` path removed.\n- **ARTIFACT_DIR is protocol output (always emitted):** Emitted once per run on stderr as a raw line: exactly `ARTIFACT_DIR=<absolute-path>` with no prefix, no timestamp, no brackets, no extra fields. Emitted immediately after batch directory creation, before any work items start. Not implemented through `LogProgress()` \u2014 uses direct `Console.Error.WriteLine()` to avoid any formatting. `--no-progress` only suppresses lifecycle transition lines (queued/running/completed/etc), never protocol lines. CI parses with: `grep '^ARTIFACT_DIR=' stderr.log | cut -d= -f2-`.\n- **Per-token evidence model:** `EvidenceEvaluation` carries `Dictionary<string, EvidenceHit>` where `EvidenceHit = { BestScore, Tier, SourceKind, SourceDetail, ProofLine }`. Merge selects strongest hit per token. Tie-breaker: higher tier > higher score > cli_output over log_fallback > stable ordering.\n- **ComputeTier \u2014 deterministic per-provider regex + token attribution:**\n  - Claude Tier 1 (primary): regex `\"name\"\\s*:\\s*\"Skill\"` on lines also containing `\"skill\"\\s*:\\s*\"(?<skill>[^\"]+)\"`. Token attribution: case-insensitive substring match of `token` in `<skill>` capture group. This is the strongest signal \u2014 direct skill identifier from tool_use JSON.\n  - Claude Tier 1 (secondary): regex `Launching skill:\\s*(?<skill>\\S+)` (score 900). Token attribution: case-insensitive substring match of `token` in `<skill>` capture group. No heuristic \"nearby context\" parsing.\n  - Codex/Copilot Tier 1: regex `Base directory for this skill:\\s*(?<path>.+)`. Token attribution: normalize `<path>` separators to `/`, then require `\"/\" + token.ToLowerInvariant() + \"/\"` present in `path.ToLowerInvariant()`. End-of-path without trailing slash also matches via `\"/\" + token.ToLowerInvariant()` at string end. If path doesn't contain the token \u2192 NOT Tier 1 for that token.\n  - All providers Tier 2: score 60-800, or Tier 1 regex match that fails token attribution.\n  - All providers Tier 3: score < 60.\n  - ScoreProofLine values are inputs. The function is pure and deterministic \u2014 no side effects, no ambient state.\n- **`expected_skill` implicit Tier 1:** Each case's `expected_skill` field is implicitly treated as a `required_skills` entry (Tier 1 gating) unless the case sets `expected_skill_min_tier: 2` to opt out. This ensures Tier 1 gating is active on the existing 14-case corpus without bulk-editing cases.json.\n- **Typed evidence requirements (explicit):** `required_skills[]` (Tier 1), `required_files[]` (Tier 2). Legacy `required_all_evidence` preserved with Tier 2 default. `expected_skill` auto-added to required_skills.\n- **Log fallback policy:** Capped at Tier 2. Diagnostics-only when max_parallel > 1. `--allow-log-fallback-pass` (default false, auto-enabled serial). `--enable-log-scan` (default off parallel, on serial).\n- **Log snapshot:** Once per agent per batch.\n- **Disallowed tier gating:** `disallowed_min_tier` (default 2). Tier 3 matches diagnostics only.\n- **Failure categories (deterministic mapping):** `timeout` if `TimedOut==true`; `transport` if process failed to start, CLI missing, or status is `infra_error`; `assertion` if evidence gating failed and not timed out. Mapping is evaluated in priority order (timeout > transport > assertion). (`parse` deferred \u2014 see PRD amendment above.)\n- **CI baseline comparison \u2014 ref-based policy:** Workflow adds a `baseline_ref` input (default: `main`). Workflow uses `actions/checkout` with `fetch-depth: 0` and explicit `git fetch origin <baseline_ref>`, then extracts baseline via `git show origin/<baseline_ref>:tests/agent-routing/provider-baseline.json`. For `schedule` runs, `baseline_ref` defaults to `main`. For `workflow_dispatch`, operator can override to compare against any branch. Note: current workflow triggers are `workflow_dispatch` + `schedule` only (no `pull_request`), so `GITHUB_BASE_REF` is not available. If a PR trigger is added in the future, `baseline_ref` can default to `$GITHUB_BASE_REF` in that context. Baseline edits in branches are allowed but regression is still detected vs the baseline ref version.\n- **CI baseline schema:** `{ expected_status: pass|fail|infra_error, allow_timeout: false }` per case per provider. Timeout comparison: `timed_out && !allow_timeout` \u2192 regression. Missing artifact/results.json \u2192 hard fail.\n- **CI baseline missing-entry policy (two-file comparison):** The summarize step loads TWO baselines: (1) the **ref baseline** from `git show origin/<baseline_ref>:tests/agent-routing/provider-baseline.json` and (2) the **current baseline** from the checked-in `tests/agent-routing/provider-baseline.json` in the working tree. Behavior:\n  - Every `(case_id, provider)` in results MUST have an entry in the **current baseline** \u2014 missing \u2192 hard failure: `\"ERROR: No baseline entry for case '<case_id>' provider '<provider>'. Update provider-baseline.json.\"`. This ensures contributors add baseline entries when adding cases.\n  - Regression comparison only applies to entries that exist in BOTH the ref baseline and results. Entries present in results + current baseline but absent from ref baseline are classified as **new coverage** (logged in delta table as `NEW`, no regression comparison). This prevents deadlocking case evolution \u2014 new cases pass CI without requiring `baseline_ref` to point at itself.\n- **CI matrix:** `fail-fast: false`. `continue-on-error: true` copilot (infra only, not regressions).\n- **Default MAX_CONCURRENCY:** 4.\n- **Retry policy / timeout+evidence:** out of scope / preserved.\n\n## Task ordering\n\nStrict sequential (no parallel work within check-skills.cs):\n\n```\nT1 (run IDs + lifecycle + failure categories)\n  \u2192 T4 (artifact isolation + concurrency + log scan + proof log)\n    \u2192 T2 (ComputeTier + per-token model + typed requirements + expected_skill implicit Tier 1)\n      \u2192 T3 (schema extensions + tier-gated disallowed + mismatch classification)\n        \u2192 T5 (CI matrix + base-branch-head baseline + regression gate)\n          \u2192 T6 (docs)\n```\n\n## Quick commands\n\n```bash\n./test.sh --agents claude --max-parallel 4\n./test.sh\n./scripts/validate-skills.sh && ./scripts/validate-marketplace.sh\n```\n\n## Acceptance\n\n- [ ] batch_run_id (UUID) in ResultEnvelope; unit_run_id (UUID) in each AgentResult\n- [ ] Lifecycle transitions on stderr with run IDs\n- [ ] `ARTIFACT_DIR=<path>` on stderr as raw line (no prefix/timestamp, always emitted, not suppressed by `--no-progress`); both results.json and tool-use-proof.log written unconditionally to batch dir\n- [ ] `--artifacts-root` overrides base; no hardcoded proof log path in test.sh\n- [ ] MAX_CONCURRENCY defaults to 4, env override, flag precedence\n- [ ] `ComputeTier(agent, token, line, score)` is single tier source of truth with explicit regexes\n- [ ] Codex/Copilot Tier 1 requires `/<token>/` in `Base directory` path (case-insensitive, normalized separators) \u2014 attribution verified\n- [ ] Deterministic self-test: `--self-test` flag runs ComputeTier against fixture inputs and asserts expected tiers (at least: Claude primary Tier 1 via `\"skill\":\"...\"` field, Claude secondary Tier 1 via `Launching skill:`, Claude Tier 2 fallback, Codex Tier 1 hit, Codex Tier 1 miss \u2192 Tier 2, Tier 3 low score)\n- [ ] `expected_skill` implicitly Tier 1 gated (existing cases enforce skill invocation, not just file reads)\n- [ ] At least one AC per provider demonstrating Tier 1 gating is active (not just implemented but unused)\n- [ ] Per-token EvidenceHit in evaluation; log_fallback capped Tier 2; diagnostics-only when parallel\n- [ ] Log snapshot once per agent per batch; scanning off when parallel by default\n- [ ] `disallowed_skills` tier-gated at min Tier 2; Tier 3 diagnostics only\n- [ ] Mismatch kinds: missing_required, disallowed_hit, optional_only, mixed\n- [ ] failure_category: timeout, transport, assertion (parse deferred with PRD amendment)\n- [ ] CI matrix with `baseline_ref` input (default `main`) for baseline comparison; `timed_out && !allow_timeout` \u2192 regression\n- [ ] Missing artifact \u2192 hard fail; missing current-baseline entry \u2192 hard fail; new case_id absent from ref baseline \u2192 `NEW` (no regression gate, logged in delta table)\n- [ ] CI matrix jobs upload artifacts with `if: always()` so summarize always has data\n- [ ] CI uses `fetch-depth: 0` and explicit `git fetch origin <baseline_ref>` for baseline ref availability\n- [ ] Operator docs updated for all features\n- [ ] All existing tests pass\n\n## References\n\n- PRD: `.flow/specs/prd-routing-reliability-and-skill-invocation.md`\n- Predecessor: fn-53\n- Key files: `test.sh`, `tests/agent-routing/check-skills.cs`, `tests/agent-routing/cases.json`, `.github/workflows/agent-live-routing.yml`, `docs/agent-routing-tests.md`\n"
  },
  "epic_id": "fn-54-agent-routing-harness-determinism-and",
  "schema_version": 2,
  "tasks": [
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T23:01:39.682946Z",
        "depends_on": [],
        "epic": "fn-54-agent-routing-harness-determinism-and",
        "id": "fn-54-agent-routing-harness-determinism-and.1",
        "priority": null,
        "spec_path": ".flow/tasks/fn-54-agent-routing-harness-determinism-and.1.md",
        "status": "todo",
        "title": "Add run ID telemetry and lifecycle progress output",
        "updated_at": "2026-02-19T23:22:53.294468Z"
      },
      "id": "fn-54-agent-routing-harness-determinism-and.1",
      "runtime": {
        "assignee": "claire@novotny.org",
        "claim_note": "",
        "claimed_at": "2026-02-20T00:33:38.445949Z",
        "evidence": {
          "commits": [
            "733c2f599f8962818c9d45d2f05ea30c3df75a76",
            "08520bb",
            "686a61e"
          ],
          "prs": [],
          "tests": [
            "./scripts/validate-skills.sh",
            "./scripts/validate-marketplace.sh",
            "dotnet run --file tests/agent-routing/check-skills.cs -- --help",
            "dotnet run --file tests/agent-routing/check-skills.cs -- --agents nonexistent --no-progress (verified batch_run_id, unit_run_id, failure_category)",
            "AGENT_FAKECLI_TEMPLATE='totally_nonexistent_binary_xyz {prompt}' dotnet run ... (verified CLI-missing -> transport)"
          ]
        },
        "status": "done",
        "updated_at": "2026-02-20T00:52:07.781256Z"
      },
      "spec": "# fn-54-agent-routing-harness-determinism-and.1 Add run ID telemetry, lifecycle progress, and failure categories\n\n## Description\nAdd batch and unit UUID run IDs, structured lifecycle progress output, and failure categories to the routing test runner so every prompt-agent unit is trackable from queue to completion.\n\n**Size:** M\n**Files:** `tests/agent-routing/check-skills.cs`\n\n## Approach\n\n- Generate `batch_run_id` (UUID v4) once per `RunAsync()` invocation; generate `unit_run_id` (UUID v4) per work item in `ExecuteWorkAsync()` (L206-257)\n- Add `batch_run_id` to `ResultEnvelope` (L1464) and `unit_run_id` to `AgentResult` (L1524)\n- Emit lifecycle transitions to stderr via `LogProgress()`: `[batch:{batch_run_id}] [unit:{unit_run_id}] {agent}:{case_id} -> {state}` where state is queued/running/completed/failed/timeout\n- Add `failure_category` field to `AgentResult` with deterministic priority-order mapping: `timeout` if `TimedOut==true`; `transport` if process failed to start, CLI missing, or status is `infra_error`; `assertion` if evidence gating failed and not timed out; null if pass. Evaluated in priority order (timeout > transport > assertion). Orthogonal to routing mismatch `failure_kind`.\n- Preserve existing `--no-progress` flag behavior (suppress stderr lifecycle transitions only). Protocol output lines (`ARTIFACT_DIR=...`) are never suppressed by `--no-progress` \u2014 they are T4's responsibility but T1 must not gate them behind `--no-progress`.\n\n## Key context\n\n- `LogProgress()` already uses `lock (_consoleLock)` for thread-safe stderr writes \u2014 reuse this\n- `results[item.Index]` pre-allocated array ensures deterministic output ordering \u2014 do not change\n- Run IDs must appear in both stderr progress AND JSON output for correlation\n- Artifact directory creation and ARTIFACT_DIR emission are T4's responsibility, not T1's\n- `parse` failure category deferred \u2014 current runner does substring matching, not structured JSON parsing\n\n## Acceptance\n- [ ] ResultEnvelope includes `batch_run_id` (UUID) \u2014 verifiable: `jq '.batch_run_id' <output> | grep -E '^[0-9a-f-]{36}$'`\n- [ ] Every AgentResult includes `unit_run_id` (UUID) \u2014 verifiable: `jq '.results[].unit_run_id' <output>`\n- [ ] unit_run_ids are unique across all results in a single execution\n- [ ] Stderr shows lifecycle transitions: queued -> running -> completed/failed/timeout per unit\n- [ ] AgentResult includes `failure_category` (timeout|transport|assertion|null)\n- [ ] `--no-progress` suppresses lifecycle output\n- [ ] Existing test cases continue to pass with no behavioral change\n\n## Done summary\nAdded batch_run_id (UUID) to ResultEnvelope and unit_run_id (UUID) to each AgentResult for cross-correlation. Implemented lifecycle progress output on stderr (queued/running/completed/failed/timeout) with run IDs. Added failure_category field with deterministic priority mapping (timeout > transport > assertion). Detects missing CLI binaries (bash exit 126/127) as transport failures. Updated operator docs with new fields and stderr format.\n## Evidence\n- Commits: 733c2f599f8962818c9d45d2f05ea30c3df75a76, 08520bb, 686a61e\n- Tests: ./scripts/validate-skills.sh, ./scripts/validate-marketplace.sh, dotnet run --file tests/agent-routing/check-skills.cs -- --help, dotnet run --file tests/agent-routing/check-skills.cs -- --agents nonexistent --no-progress (verified batch_run_id, unit_run_id, failure_category), AGENT_FAKECLI_TEMPLATE='totally_nonexistent_binary_xyz {prompt}' dotnet run ... (verified CLI-missing -> transport)\n- PRs:"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T23:01:39.783719Z",
        "depends_on": [
          "fn-54-agent-routing-harness-determinism-and.4"
        ],
        "epic": "fn-54-agent-routing-harness-determinism-and",
        "id": "fn-54-agent-routing-harness-determinism-and.2",
        "priority": null,
        "spec_path": ".flow/tasks/fn-54-agent-routing-harness-determinism-and.2.md",
        "status": "todo",
        "title": "Promote evidence scoring to tier-based gating for required assertions",
        "updated_at": "2026-02-19T23:56:55.398484Z"
      },
      "id": "fn-54-agent-routing-harness-determinism-and.2",
      "runtime": {
        "assignee": "claire@novotny.org",
        "claim_note": "",
        "claimed_at": "2026-02-20T01:09:37.219868Z",
        "evidence": {
          "commits": [
            "f685a78",
            "577b8ce",
            "746498b",
            "fa140c0",
            "794ba1e",
            "fbba803",
            "30794ad"
          ],
          "prs": [],
          "tests": [
            "dotnet run --file tests/agent-routing/check-skills.cs -- --self-test",
            "./scripts/validate-skills.sh",
            "./scripts/validate-marketplace.sh"
          ]
        },
        "status": "done",
        "updated_at": "2026-02-20T01:59:33.621521Z"
      },
      "spec": "# fn-54-agent-routing-harness-determinism-and.2 Reshape evidence evaluation to per-token tier-gated model\n\n## Description\nReshape evidence evaluation to per-token best-hit with `ComputeTier(agent, token, line, score)` as single source of truth. Implement explicit per-provider regexes with token attribution, and make `expected_skill` implicitly Tier 1 gated.\n\n**Size:** M\n**Files:** `tests/agent-routing/check-skills.cs`\n\n## Approach\n\n- Define `EvidenceHit` record: `{ string Token, int BestScore, int Tier, string SourceKind, string SourceDetail, string ProofLine }`\n- Extend `EvidenceEvaluation` with `Dictionary<string, EvidenceHit> TokenHits`\n- Implement `ComputeTier(string agent, string token, string line, int score)` \u2014 pure, deterministic, no side effects:\n  - **Claude Tier 1 (primary):** regex `\"name\"\\s*:\\s*\"Skill\"` on lines also containing `\"skill\"\\s*:\\s*\"(?<skill>[^\"]+)\"`. Token attribution: case-insensitive substring match of `token` in `<skill>` capture group. This is the strongest signal \u2014 direct skill identifier from tool_use JSON.\n  - **Claude Tier 1 (secondary):** regex `Launching skill:\\s*(?<skill>\\S+)` (score 900). Token attribution: case-insensitive substring match of `token` in `<skill>` capture group. No heuristic \"nearby context\" parsing.\n  - **Codex/Copilot Tier 1:** regex `Base directory for this skill:\\s*(?<path>.+)`. Token attribution: normalize `<path>` separators to `/`, then require `\"/\" + token.ToLowerInvariant() + \"/\"` in `path.ToLowerInvariant()`. End-of-path match: also match `\"/\" + token.ToLowerInvariant()` at string end. If path doesn't contain the token \u2192 NOT Tier 1 (falls to Tier 2).\n  - **All Tier 2:** score 60-800, or Tier 1 regex hit that fails token attribution.\n  - **All Tier 3:** score < 60.\n  - ScoreProofLine values are inputs, not tier definitions.\n- Add `--self-test` flag: runs ComputeTier against built-in fixture inputs and asserts expected tiers. Fixtures must include at minimum: Claude primary Tier 1 hit (tool_use JSON with `\"name\":\"Skill\"` + `\"skill\":\"dotnet-xunit\"`), Claude secondary Tier 1 hit (`Launching skill: dotnet-xunit`), Claude Tier 2 fallback (Tier 1 regex without token attribution), Codex Tier 1 hit (path contains `/dotnet-xunit/`), Codex Tier 1 miss \u2192 Tier 2 (path lacks token), Tier 3 low score. Exits 0 on pass, 1 on failure with diff output. Invocation: `dotnet run --file tests/agent-routing/check-skills.cs -- --self-test`.\n- Tie-breaker for per-token best-hit: higher tier > higher score > cli_output over log_fallback > stable ordering\n- `expected_skill` implicit Tier 1: each case's `expected_skill` field auto-added to `required_skills[]` (Tier 1 gating) unless case sets `expected_skill_min_tier: 2`. This ensures Tier 1 gating is active on existing 14 cases without bulk-editing cases.json.\n- Typed requirements: `required_skills[]` (Tier 1), `required_files[]` (Tier 2). Legacy `required_all_evidence` preserved with Tier 2 default. Normalization: if a legacy `required_all_evidence` token matches the pattern of a skill ID (i.e., it's also present in `expected_skill` or `required_skills`), it is treated as a `required_skills` entry in the new model to avoid contradictory tiering.\n- `EvidenceEvaluation.Merge()`: select strongest hit per token, cap all log_fallback at Tier 2\n- When `MaxParallel > 1`: log_fallback diagnostics-only. `--allow-log-fallback-pass` (default false, auto serial).\n- Log scanning: uses per-agent-per-batch snapshot from T4. Off when parallel by default.\n- `weak_evidence_only` failure kind when all evidence is Tier 3\n\n## Key context\n\n- `ScoreProofLine()` at L729-774 produces scores \u2014 inputs to ComputeTier\n- `EvidenceEvaluation.Merge()` at L1382 merges without strength \u2014 this gets reshaped\n- `BuildRequiredAllEvidence()` at L863 has Claude SKILL.md skipping \u2014 compatible with tier system\n- Generic file reads remain Tier 2 for ALL providers \u2014 prevents \"read the docs\" false positives\n- `expected_skill` is present on all 14 existing cases \u2014 implicit Tier 1 activates gating immediately\n\n## Acceptance\n- [ ] `ComputeTier(agent, token, line, score)` exists with explicit regexes per provider\n- [ ] Claude Tier 1 (primary): `\"name\":\"Skill\"` + `\"skill\":\"<id>\"` on same line \u2014 token attribution via `<id>` capture. Verifiable: tool_use JSON with `\"skill\":\"dotnet-xunit\"` \u2192 Tier 1 for `dotnet-xunit`\n- [ ] Claude Tier 1 (secondary): `Launching skill:` with token attribution \u2014 verifiable: `Launching skill: dotnet-xunit` \u2192 Tier 1 for `dotnet-xunit`\n- [ ] Codex/Copilot Tier 1: `Base directory for this skill:` requires `/<token>/` in path (case-insensitive, normalized separators) \u2014 verifiable: path `/skills/testing/dotnet-xunit/SKILL.md` \u2192 Tier 1 for `dotnet-xunit`; path without token \u2192 Tier 2\n- [ ] `--self-test` flag: runs ComputeTier against fixture inputs, asserts expected tiers, exits 0 \u2014 verifiable: `dotnet run --file tests/agent-routing/check-skills.cs -- --self-test`\n- [ ] `expected_skill` auto-added to required_skills (Tier 1) \u2014 verifiable: existing case with expected_skill `dotnet-xunit` requires Tier 1 evidence for that skill\n- [ ] `expected_skill_min_tier: 2` opt-out works \u2014 verifiable: case with opt-out accepts Tier 2\n- [ ] EvidenceEvaluation carries `TokenHits` with per-token `EvidenceHit`\n- [ ] Tie-breaker: higher tier > higher score > cli_output > log_fallback > stable\n- [ ] Legacy `required_all_evidence` defaults Tier 2 \u2014 all 14 cases pass\n- [ ] log_fallback capped Tier 2; diagnostics-only when parallel; `--allow-log-fallback-pass` auto serial\n- [ ] `weak_evidence_only` emitted when only Tier 3 evidence found\n\n## Done summary\nImplemented tier-based evidence gating with ComputeTier as single source of truth for per-provider regex + token attribution. Added 14 self-test fixtures, typed requirements (required_skills Tier 1, required_files Tier 2), implicit Tier 1 for expected_skill, log_fallback Tier 2 cap enforced during evaluation, diagnostics-only merge in fail paths, and updated docs.\n## Evidence\n- Commits: f685a78, 577b8ce, 746498b, fa140c0, 794ba1e, fbba803, 30794ad\n- Tests: dotnet run --file tests/agent-routing/check-skills.cs -- --self-test, ./scripts/validate-skills.sh, ./scripts/validate-marketplace.sh\n- PRs:"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T23:01:39.884438Z",
        "depends_on": [
          "fn-54-agent-routing-harness-determinism-and.2"
        ],
        "epic": "fn-54-agent-routing-harness-determinism-and",
        "id": "fn-54-agent-routing-harness-determinism-and.3",
        "priority": null,
        "spec_path": ".flow/tasks/fn-54-agent-routing-harness-determinism-and.3.md",
        "status": "todo",
        "title": "Extend case schema with optional, disallowed, and provider alias fields",
        "updated_at": "2026-02-19T23:23:30.122286Z"
      },
      "id": "fn-54-agent-routing-harness-determinism-and.3",
      "runtime": {
        "assignee": "claire@novotny.org",
        "claim_note": "",
        "claimed_at": "2026-02-20T02:04:35.586002Z",
        "evidence": {
          "commits": [
            "1ab463b",
            "20f4518",
            "bd77bd4"
          ],
          "prs": [],
          "tests": [
            "dotnet run --file tests/agent-routing/check-skills.cs -- --self-test",
            "./scripts/validate-skills.sh",
            "./scripts/validate-marketplace.sh"
          ]
        },
        "status": "done",
        "updated_at": "2026-02-20T02:34:16.288377Z"
      },
      "spec": "# fn-54-agent-routing-harness-determinism-and.3 Extend case schema with optional, disallowed, and provider alias fields\n\n## Description\nExtend the `CaseDefinition` schema with `optional_skills`, `disallowed_skills`, and `provider_aliases` fields. Integrate with T2's tier-aware evaluation for granular mismatch classification with tier-gated disallowed detection.\n\n**Size:** M\n**Files:** `tests/agent-routing/check-skills.cs`, `tests/agent-routing/cases.json`\n\n## Approach\n\n- Add fields to `CaseDefinition` (L1332): `optional_skills: string[]`, `disallowed_skills: string[]`, `provider_aliases: Dictionary<string, Dictionary<string, string>>`, `disallowed_min_tier: int` (default 2)\n- `disallowed_skills` check: after evidence evaluation, if any disallowed skill token appears in `TokenHits` at or above `disallowed_min_tier`, classify as `disallowed_hit`. Tier 3 disallowed matches reported in diagnostics only (not failure-causing) to avoid false positives from weak mentions.\n- `optional_skills`: track matches in `TokenHits` diagnostics. Output as `optional_hits[]` in AgentResult. Excluded from pass/fail gating.\n- `provider_aliases`: resolve agent-specific skill names to canonical names before evidence matching. Integrates with `AddSkillVariants()` which already handles colon-separated prefixes.\n- Granular mismatch reasons in `ClassifyFailure()`: `missing_required` (required token missing or below min tier), `disallowed_hit` (disallowed token found at >= min tier), `optional_only` (only optional skills matched, no required), `mixed` (multiple failure reasons)\n- New fields default to empty \u2014 all 14 existing cases pass unchanged\n\n## Key context\n\n- T2 must be completed first: disallowed/optional matching uses `TokenHits` and `ComputeTier`\n- `disallowed_min_tier` default 2 prevents Tier 3 weak mentions from triggering false disallowed failures \u2014 mirrors the same \"weak evidence\" problem from the original false-positive vector\n- `AddSkillVariants()` already handles colon-separated prefixes \u2014 provider_aliases extends this\n- All 14 existing cases use `required_all_evidence` and `required_any_evidence` only\n\n## Acceptance\n- [ ] CaseDefinition supports `optional_skills`, `disallowed_skills`, `provider_aliases`, `disallowed_min_tier` fields\n- [ ] New fields default to empty/2 (all 14 existing cases pass unchanged)\n- [ ] Disallowed skill at >= Tier 2 produces `disallowed_hit` failure\n- [ ] Disallowed skill at Tier 3 only appears in diagnostics, not failure classification\n- [ ] `disallowed_min_tier` per-case override works \u2014 verifiable: case with `disallowed_min_tier: 1` fails on Tier 1 hit\n- [ ] Optional skill matches in `optional_hits[]` in AgentResult JSON, no pass/fail impact\n- [ ] Provider aliases resolved before evidence matching\n- [ ] ClassifyFailure returns: missing_required, disallowed_hit, optional_only, mixed\n\n## Done summary\nExtended CaseDefinition with optional_skills, disallowed_skills, provider_aliases, and disallowed_min_tier fields. Implemented tier-gated disallowed detection (Tier 3 diagnostics-only), optional skill tracking in optional_hits[], provider alias resolution before evidence matching, and granular ClassifyFailure mismatch kinds (missing_required, disallowed_hit, optional_only, mixed). Self-test extended with 9 T3-specific fixtures.\n## Evidence\n- Commits: 1ab463b, 20f4518, bd77bd4\n- Tests: dotnet run --file tests/agent-routing/check-skills.cs -- --self-test, ./scripts/validate-skills.sh, ./scripts/validate-marketplace.sh\n- PRs:"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T23:01:39.985263Z",
        "depends_on": [
          "fn-54-agent-routing-harness-determinism-and.1"
        ],
        "epic": "fn-54-agent-routing-harness-determinism-and",
        "id": "fn-54-agent-routing-harness-determinism-and.4",
        "priority": null,
        "spec_path": ".flow/tasks/fn-54-agent-routing-harness-determinism-and.4.md",
        "status": "todo",
        "title": "Isolate artifacts per run ID and set concurrency bounds",
        "updated_at": "2026-02-19T23:29:17.890041Z"
      },
      "id": "fn-54-agent-routing-harness-determinism-and.4",
      "runtime": {
        "assignee": "claire@novotny.org",
        "claim_note": "",
        "claimed_at": "2026-02-20T00:55:26.346192Z",
        "evidence": {
          "commits": [
            "f661257",
            "b43df0e"
          ],
          "prs": [],
          "tests": [
            "./scripts/validate-skills.sh && ./scripts/validate-marketplace.sh",
            "grep -c PROOF_LOG test.sh"
          ]
        },
        "status": "done",
        "updated_at": "2026-02-20T01:05:53.248271Z"
      },
      "spec": "# fn-54-agent-routing-harness-determinism-and.4 Isolate all artifacts per batch, set concurrency, optimize log scanning\n\n## Description\nIsolate ALL per-run artifacts (results.json AND tool-use-proof.log) into batch-run-ID directories. Add `--artifacts-root`, emit `ARTIFACT_DIR`, set MAX_CONCURRENCY, optimize log snapshot to per-agent-per-batch.\n\n**Size:** M\n**Files:** `tests/agent-routing/check-skills.cs`, `test.sh`\n\n## Approach\n\n- T4 consumes `batch_run_id` (generated by T1) for all artifact functionality:\n  - Create `<artifacts-root>/<batch_run_id>/` at start of `RunAsync()`\n  - Runner always writes `<batch_run_id>/results.json` and `<batch_run_id>/tool-use-proof.log` unconditionally (no per-unit subdirectories \u2014 deferred until concrete per-unit artifacts exist). `--output` preserved for backward compat (writes additional copy) but batch dir copy is the source of truth. JSON also written to stdout as before (convenience copy)\n  - No separate `--proof-log` needed \u2014 default resolves under batch dir\n  - Emit `ARTIFACT_DIR=<absolute-path>` as a raw line on stderr via `Console.Error.WriteLine()` (NOT through `LogProgress()`) \u2014 no prefix, no timestamp, no brackets. Emitted once immediately after batch directory creation. This is **protocol output** (always emitted, never suppressed by `--no-progress`). CI parses with: `grep '^ARTIFACT_DIR=' stderr.log | cut -d= -f2-`\n- Add `--artifacts-root <path>` to `RunnerOptions.Parse()` (default: `tests/agent-routing/artifacts`)\n- Remove hardcoded `PROOF_LOG` from test.sh (L8). test.sh no longer needs to manage proof log path \u2014 runner handles it.\n- MAX_CONCURRENCY: default 4, `MAX_CONCURRENCY` env fallback, `--max-parallel` flag precedence\n- Log snapshot: `CaptureLogSnapshot()` once per agent per batch (before scheduling), stored in `Dictionary<string, LogSnapshot>`\n- `--enable-log-scan` flag: off when max_parallel > 1, on when serial. Aligns with T2's log_fallback policy.\n- Update test.sh `--help` for all new options\n\n## Key context\n\n- Current `PROOF_LOG` in test.sh (L8) is single shared path \u2014 collision point. Removing it and defaulting under batch dir fixes this.\n- `trap cleanup EXIT` in test.sh (L196) cleans `apps/` \u2014 do not change\n- Memory: \"Sole owner for parallel file creation\" \u2014 runner creates batch dir, not test.sh\n- Memory: \"GHA script | tee exit code loss\" \u2014 preserve exit codes\n\n## Acceptance\n- [ ] results.json at `<artifacts-root>/<batch_run_id>/results.json` \u2014 verifiable: `ls artifacts/*/results.json`\n- [ ] tool-use-proof.log at `<artifacts-root>/<batch_run_id>/tool-use-proof.log` \u2014 verifiable: `ls artifacts/*/tool-use-proof.log`\n- [ ] `ARTIFACT_DIR=<path>` on stderr as raw line (no prefix/timestamp) \u2014 verifiable: `./test.sh --no-progress 2>&1 | grep '^ARTIFACT_DIR='`\n- [ ] results.json written unconditionally to batch dir (no --output needed) \u2014 verifiable: run without --output, file exists\n- [ ] `--artifacts-root` overrides base \u2014 verifiable: `--artifacts-root /tmp/test-arts` writes there\n- [ ] test.sh has NO hardcoded `PROOF_LOG` path \u2014 verifiable: `grep -c PROOF_LOG test.sh` returns 0\n- [ ] No collision: two sequential runs \u2192 different batch directories\n- [ ] MAX_CONCURRENCY: default 4, env override, flag precedence\n- [ ] `CaptureLogSnapshot()` once per agent per batch, not per unit\n- [ ] `--enable-log-scan`: off when parallel, on when serial\n- [ ] test.sh `--help` documents all new options\n\n## Done summary\nIsolate all per-run artifacts (results.json, tool-use-proof.log) into batch-run-ID directories under --artifacts-root, emit ARTIFACT_DIR protocol output on stderr, set MAX_CONCURRENCY default to 4 with env/flag precedence, gate log scanning behind --enable-log-scan (on serial, off parallel), and remove hardcoded PROOF_LOG from test.sh.\n## Evidence\n- Commits: f661257, b43df0e\n- Tests: ./scripts/validate-skills.sh && ./scripts/validate-marketplace.sh, grep -c PROOF_LOG test.sh\n- PRs:"
    },
    {
      "data": {
        "assignee": null,
        "claim_note": "",
        "claimed_at": null,
        "created_at": "2026-02-19T23:01:40.087590Z",
        "depends_on": [
          "fn-54-agent-routing-harness-determinism-and.1",
          "fn-54-agent-routing-harness-determinism-and.4",
          "fn-54-agent-routing-harness-determinism-and.3"
        ],
        "epic": "fn-54-agent-routing-harness-determinism-and",
        "id": "fn-54-agent-routing-harness-determinism-and.5",
        "priority": null,
        "spec_path": ".flow/tasks/fn-54-agent-routing-harness-determinism-and.5.md",
        "status": "todo",
        "title": "Convert CI to provider matrix with regression guardrails",
        "updated_at": "2026-02-19T23:56:55.588377Z"
      },
      "id": "fn-54-agent-routing-harness-determinism-and.5",
      "runtime": {
        "assignee": "claire@novotny.org",
        "claim_note": "",
        "claimed_at": "2026-02-20T02:38:17.863495Z",
        "evidence": {
          "commits": [
            "ae20b6e8fba10c7424af804796336b884b87c6fe",
            "e95cefb"
          ],
          "prs": [],
          "tests": [
            "./scripts/validate-skills.sh && ./scripts/validate-marketplace.sh"
          ]
        },
        "status": "done",
        "updated_at": "2026-02-20T02:55:07.175490Z"
      },
      "spec": "# fn-54-agent-routing-harness-determinism-and.5 Convert CI to provider matrix with ref-based regression guardrails\n\n## Description\nConvert CI routing workflow to GHA strategy matrix with per-provider artifacts, ref-based baseline comparison via `baseline_ref` input, and mechanically enforceable regression gate including timeout and missing-artifact handling.\n\n**Size:** M\n**Files:** `.github/workflows/agent-live-routing.yml`, `tests/agent-routing/provider-baseline.json` (new)\n\n## Approach\n\n- Matrix: `agent: [claude, codex, copilot]`, `fail-fast: false`\n- Each job: run `test.sh --agents ${{ matrix.agent }}`, parse `ARTIFACT_DIR=<path>` from stderr via `grep '^ARTIFACT_DIR=' stderr.log | cut -d= -f2-`, upload `routing-results-${{ matrix.agent }}` with `if: always()`\n- `continue-on-error: true` copilot (infra only, not regressions)\n- `summarize` job: `needs: [routing-test]`, `if: always()`, downloads via `pattern: routing-results-*` + `merge-multiple: true`\n- `provider-baseline.json` schema: `{ \"case_id\": { \"claude\": { \"expected_status\": \"pass|fail|infra_error\", \"allow_timeout\": false }, ... } }`\n- **Baseline comparison source-of-truth (ref-based, explicit):**\n  - Add `baseline_ref` input to `workflow_dispatch` (type: string, default: `main`). For `schedule` runs, hardcode `main` as the baseline ref.\n  - Workflow uses `actions/checkout` with `fetch-depth: 0` to ensure all refs are available.\n  - Summarize step runs `git fetch origin <baseline_ref>` before baseline extraction.\n  - Extract baseline via `git show origin/<baseline_ref>:tests/agent-routing/provider-baseline.json`.\n  - Note: current triggers are `workflow_dispatch` + `schedule` only \u2014 `GITHUB_BASE_REF` is not available. If a PR trigger is added in the future, `baseline_ref` can default to `$GITHUB_BASE_REF` in that context.\n  - Baseline edits in branches are allowed but regression is still detected vs the baseline ref version.\n- Comparison rules:\n  - `pass -> fail` or `pass -> infra_error` vs baseline \u2192 REGRESSION (hard fail)\n  - `timed_out=true` AND `allow_timeout=false` \u2192 REGRESSION\n  - `timed_out=true` AND `allow_timeout=true` \u2192 ALLOWED\n  - `fail -> pass` \u2192 IMPROVEMENT (informational, logged in delta table)\n  - Missing provider artifact or results.json \u2192 HARD FAIL for that provider\n  - **Missing-entry policy (two-file comparison):** Summarize loads TWO baselines: (1) **ref baseline** from `git show origin/<baseline_ref>:...` and (2) **current baseline** from the working tree `tests/agent-routing/provider-baseline.json`.\n    - Every `(case_id, provider)` in results MUST exist in the **current baseline** \u2014 missing \u2192 HARD FAIL: `\"ERROR: No baseline entry for case '<case_id>' provider '<provider>'. Update provider-baseline.json.\"`\n    - Regression comparison only for entries present in BOTH ref baseline and results. Entries in results + current baseline but absent from ref baseline \u2192 `NEW` coverage (logged in delta table, no regression comparison). This prevents deadlocking new-case addition.\n- Delta table in job summary: case_id | claude | codex | copilot | delta (where delta is REGRESSION, IMPROVEMENT, NEW, or OK)\n\n## Key context\n\n- Current workflow (L26) is single job with 20-min timeout \u2014 matrix jobs each get own timeout\n- upload-artifact v4 requires unique names per matrix dimension\n- GHA matrix outputs: only last iteration accessible \u2014 must use artifacts\n- Memory: \"CI validation location must be specified\" \u2014 regression comparison in summarize job only\n- Current triggers are `workflow_dispatch` + `schedule` only \u2014 `GITHUB_BASE_REF` is empty in these contexts. Use `baseline_ref` input instead.\n- `git show origin/<baseline_ref>:...` requires explicit `git fetch origin <baseline_ref>` and `fetch-depth: 0` to ensure ref availability\n\n## Acceptance\n- [ ] `strategy.matrix.agent: [claude, codex, copilot]` with `fail-fast: false` \u2014 verifiable: grep in workflow\n- [ ] Each job uploads `routing-results-${{ matrix.agent }}`\n- [ ] Summarize downloads and merges all provider artifacts\n- [ ] Workflow adds `baseline_ref` input (default: `main`) \u2014 verifiable: grep `baseline_ref` in workflow\n- [ ] Workflow uses `fetch-depth: 0` and explicit `git fetch origin <baseline_ref>` \u2014 verifiable: grep in workflow\n- [ ] Baseline comparison uses `baseline_ref` input for all trigger types \u2014 no dependency on `GITHUB_BASE_REF`\n- [ ] `provider-baseline.json` uses `expected_status: pass|fail|infra_error` + `allow_timeout`\n- [ ] `pass -> fail` regression \u2192 CI fails\n- [ ] `timed_out + !allow_timeout` \u2192 regression detected\n- [ ] Missing artifact \u2192 hard fail for that provider\n- [ ] Missing current-baseline entry for (case_id, provider) \u2192 hard fail with targeted error message\n- [ ] New case_id absent from ref baseline but present in current baseline \u2192 `NEW` in delta table (no regression gate)\n- [ ] Delta table in summary\n- [ ] Copilot `continue-on-error` does NOT suppress regression gate\n- [ ] Each matrix job uploads artifacts with `if: always()` to ensure summarize has data even on failure\n\n## Done summary\nConverted CI routing workflow to GHA strategy matrix (claude, codex, copilot) with ref-based baseline comparison via baseline_ref input and mechanically enforceable regression gate. Added provider-baseline.json with per-case per-provider expected_status and allow_timeout fields, two-file baseline comparison policy, delta table in job summary, and hard-fail on regressions, missing artifacts, and missing baseline entries.\n## Evidence\n- Commits: ae20b6e8fba10c7424af804796336b884b87c6fe, e95cefb\n- Tests: ./scripts/validate-skills.sh && ./scripts/validate-marketplace.sh\n- PRs:"
    },
    {
      "data": {
        "created_at": "2026-02-19T23:01:40.186244Z",
        "depends_on": [
          "fn-54-agent-routing-harness-determinism-and.1",
          "fn-54-agent-routing-harness-determinism-and.2",
          "fn-54-agent-routing-harness-determinism-and.3",
          "fn-54-agent-routing-harness-determinism-and.4",
          "fn-54-agent-routing-harness-determinism-and.5"
        ],
        "epic": "fn-54-agent-routing-harness-determinism-and",
        "id": "fn-54-agent-routing-harness-determinism-and.6",
        "priority": null,
        "spec_path": ".flow/tasks/fn-54-agent-routing-harness-determinism-and.6.md",
        "status": "todo",
        "title": "Update operator docs for telemetry, evidence tiers, and provider matrix",
        "updated_at": "2026-02-20T07:27:42.324193Z"
      },
      "id": "fn-54-agent-routing-harness-determinism-and.6",
      "runtime": {
        "assignee": "claire@novotny.org",
        "claimed_at": "2026-02-20T07:31:51.616251Z",
        "evidence": {
          "acceptance": {
            "ac1_run_ids": "grep 'Run IDs' finds section heading",
            "ac2_evidence_tiers": "grep 'Evidence Tiers' finds section with ComputeTier",
            "ac3_log_fallback": "grep 'Log Fallback' finds policy section",
            "ac4_failure_categories": "grep 'Failure Categories' finds timeout/transport/assertion docs",
            "ac5_case_schema": "grep 'Case Schema' finds schema documentation",
            "ac6_targeted_reruns": "grep 'Targeted Reruns' finds rerun examples",
            "ac7_provider_matrix": "grep 'Provider Matrix' finds CI matrix section",
            "ac8_taxonomy": "All terms present: weak_evidence_only, disallowed_hit, optional_only, mixed, timeout, transport, assertion",
            "ac9_help": "test.sh --help documents --max-parallel, --artifacts-root, --enable-log-scan, --self-test, MAX_CONCURRENCY"
          },
          "commits": [
            "99e268f",
            "71019c4"
          ],
          "tests": [
            "validate-skills.sh PASSED",
            "validate-marketplace.sh PASSED"
          ]
        },
        "status": "done",
        "updated_at": "2026-02-20T07:36:10.532775Z"
      },
      "spec": "# fn-54-agent-routing-harness-determinism-and.6 Update operator docs for telemetry, evidence tiers, and provider matrix\n\n## Description\nUpdate operator documentation for all new harness features: run IDs, lifecycle telemetry, ComputeTier function, typed requirements, failure categories, log scan gating, disallowed tier gating, provider matrix, and targeted reruns.\n\n**Size:** S\n**Files:** `docs/agent-routing-tests.md`, `test.sh` (help block only)\n\n## Approach\n\n- \"Run IDs and Telemetry\" section: batch_run_id/unit_run_id, lifecycle transitions, ARTIFACT_DIR discovery\n- \"Evidence Tiers\" section: ComputeTier function, provider-aware Tier 1 signals (Claude: tool_use/Launching; Codex/Copilot: Base directory marker only), per-token best-hit model, typed requirements (required_skills vs required_files vs legacy required_all_evidence)\n- \"Log Fallback Policy\" section: Tier 2 cap, diagnostics-only when parallel, --allow-log-fallback-pass, --enable-log-scan flags\n- \"Failure Categories\" section: timeout/transport/assertion (parse deferred). Distinction from mismatch failure_kind.\n- \"Case Schema\" section: required_skills, required_files, optional_skills, disallowed_skills (with disallowed_min_tier), provider_aliases\n- \"Targeted Reruns\" section with examples: `./test.sh --agents claude --case-id foundation-version-detection`\n- \"Provider Matrix and Deltas\" section: CI matrix, baseline schema, regression rules, timeout handling, missing artifact behavior\n- Update failure taxonomy table: mismatch kinds (weak_evidence_only, disallowed_hit, optional_only, mixed) + categories (timeout, transport, assertion)\n\n## Key context\n\n- Current doc (110 lines) covers: files, commands, source setup, filters, evidence semantics, env vars, troubleshooting\n- Memory: \"grep-verifiable ACs\" \u2014 each section verifiable by unique heading\n\n## Acceptance\n- [ ] `grep \"Run IDs\" docs/agent-routing-tests.md` finds telemetry section\n- [ ] `grep \"Evidence Tiers\" docs/agent-routing-tests.md` finds tier explanation with ComputeTier\n- [ ] `grep \"Log Fallback\" docs/agent-routing-tests.md` finds fallback policy section\n- [ ] `grep \"Failure Categories\" docs/agent-routing-tests.md` finds timeout/transport/assertion docs\n- [ ] `grep \"Case Schema\" docs/agent-routing-tests.md` finds schema documentation\n- [ ] `grep \"Targeted Reruns\" docs/agent-routing-tests.md` finds rerun examples\n- [ ] `grep \"Provider Matrix\" docs/agent-routing-tests.md` finds CI matrix section\n- [ ] Failure taxonomy includes: weak_evidence_only, disallowed_hit, optional_only, mixed, timeout, transport, assertion\n- [ ] test.sh --help documents --max-parallel, --artifacts-root, --enable-log-scan, --self-test, MAX_CONCURRENCY\n\n## Done summary\nUpdated operator docs (docs/agent-routing-tests.md) and test.sh help block for all harness features from T1-T5.\n\n### Changes\n- docs/agent-routing-tests.md: Added sections for Run IDs and Telemetry, Evidence Tiers (ComputeTier, per-token model, self-test), Log Fallback Policy, Failure Categories (failure_kind + failure_category), Case Schema (all fields including typed requirements, provider aliases), Targeted Reruns, Provider Matrix and Deltas (CI matrix, baseline schema, regression rules, timeout/missing handling)\n- test.sh: Help block documents --max-parallel, --artifacts-root, --enable-log-scan, --self-test, MAX_CONCURRENCY, and all other runner flags\n- All 9 grep-verifiable ACs pass\n- Validation passes (0 errors)\n- Commits: 99e268f, 71019c4\n## Evidence\n- Commits: 99e268f, 71019c4\n- Tests: validate-skills.sh PASSED, validate-marketplace.sh PASSED\n- PRs:"
    }
  ]
}
